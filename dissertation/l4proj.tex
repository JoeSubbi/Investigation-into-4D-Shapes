% REMEMBER: You must not plagiarise anything in your report. Be extremely careful.

\documentclass{l4proj}

% put any additional packages here
\usepackage{amsmath}
\usepackage{pdfpages}
\usepackage{float}
\usepackage{cleveref}
\usepackage{multicol}

\begin{document}

%==============================================================================
%% METADATA
\title{Evaluating the Effectiveness of Extensions to 3D Cross Sections of 4D Geometry in the Teaching and Manipulation of this Geometry}
%\title{An Investigation into Extending a 3D Cross Section of 4D Geometry and Evaluate an Extensions Effectiveness in Teaching Users to Manipulating This Geometry}
\author{Joe Subbiani}
\date{March 18, 2022}

\maketitle

%==============================================================================
%% ABSTRACT
\begin{abstract}
    %Every abstract follows a similar pattern. Motivate; set aims; describe work; explain results.
    %\vskip 0.5em
    %``XYZ is bad. This project investigated ABC to determine if it was! better. ABC used XXX and YYY to implement ZZZ. This is particularly interesting as XXX and YYY have never been used together. It was found that ABC was 20\% better than XYZ, though it caused rabies in half of subjects.''

    Four dimensional space is a mathematical concept that cannot be visualised in its entirety by humans. Several paradigms exist to visualise four dimensional objects in 3D, but a viewer will only be able to see a fraction of a 4D object at one time.
    \vskip 0.5em
    Ray marching over signed distance functions provide a quick method of rendering 3D cross sections of a wide range of primitive 4D shapes.
    3D cross sections of 4D objects provides a platform to develop extended visualisations to provide a user with more information about a 4D object. Such extensions have been explored in other literature. This paper aims to evaluate the effectiveness of a series of extensions to 3D cross sections of 4D objects; each representation providing the user with more information in order to help them interpret and manipulate the object they are handling.
    \vskip 0.5em

    TODO: Results of Experiment
    It was found that ...
    
\end{abstract}

%==============================================================================
%% ACKNOWLEDGEMENTS
\renewcommand{\abstractname}{Acknowledgements}
\begin{abstract}
    I would like to thank my supervisor, Dr. John Williamson for the constant support and advice throughout the project, within and outside of the weekly meetings. Thanks to his guidance and support, I was able to take this project as far as I have, and fully explore the complexities of the fourth dimension.
\end{abstract}
%==============================================================================

% EDUCATION REUSE CONSENT FORM
% If you consent to your project being shown to future students for educational purposes then insert your name and the date below to  sign the education use form that appears in the front of the document. You must explicitly give consent if you wish to do so. If you sign, your project may be included in the Hall of Fame if it scores particularly highly.

% Please note that you are under no obligation to sign  this declaration, but doing so would help future students.

\def\consentname {Dominic Joe Subbiani} % your full name
\def\consentdate {24 January 2022} % the date you agree

\educationalconsent


%==============================================================================
\tableofcontents

%==============================================================================
%% Notes on formatting
%==============================================================================
% The first page, abstract and table of contents are numbered using Roman numerals and are not included in the page count. 

% From now on pages are numbered using Arabic numerals. Therefore, immediately after the first call to \chapter we need the call \pagenumbering{arabic} and this should be called once only in the document. 

% Do not alter the bibliography style.

% The first Chapter should then be on page 1. You are allowed 40 pages for a 40 credit project and 30 pages for a 20 credit report. This includes everything numbered in Arabic numerals (excluding front matter) up to but excluding the appendices and bibliography.

% You must not alter text size (it is currently 10pt) or alter margins or spacing.

%==================================================================================================================================

% IMPORTANT
% The chapter headings here are **suggestions**. You don't have to follow this model if it doesn't fit your project. Every project should have an introduction and conclusion, however. 

%==================================================================================================================================
\chapter{Introduction}

% reset page numbering. Don't remove this!
\pagenumbering{arabic} 

\section{The Fourth Dimension}

The world is described as three dimensional Euclidean space, conventionally referred to as $\mathbb{R}^3$. Three axes, conventionally labeled \(x\), \(y\) and \(z\), define the three degrees of translational freedom an entity can move within. All three axes that make up Euclidean space exist perpendicular to each other. Four dimensional space, conventionally referred to as $\mathbb{R}^4$, is the mathematical concept where a fourth perpendicular axes, conventionally labeled \(w\), exists perpendicular to all of the other three dimensional axes. It is impossible to visualise four dimensions in its entirety and often must be abstracted to an analogues 3D to 2D example to reason and understand the behaviour of four dimensional entities. 

\section{Opportunities for Exploration}

Handling four dimensional space presents a number of opportunities and challenges that come with the desire to explore, interpret and manipulate higher dimensional objects. The most immediate challenge is that of being able to manipulate a four dimensional object. Rotating an object in a dimensional space greater than two is a non trivial challenge. The most common method of rotation in 3D cannot be extended to higher dimensions. There are several ways in which users can interact with 3D objects; another non-trivial challenge is finding intuitive ways in which a user can manipulate a 4D object through a two dimensional user interface.
\vskip 0.5em
To understand the orientation of an object, a user needs to be able to differentiate similar faces of that object from each other. Colour, patterns and textures can be applied to an object in order to assist in comprehending the current pose of an object in comparison to an otherwise visually similar counterpart. An example of this is a cube rotated 90 degrees (\(\frac{\pi}{2}\) radians) and the same cube rotated by 270 degrees (\(\frac{3\pi}{2}\) radians). The un-textured cubes would appear to be the same despite not being in the same orientation.
\vskip 0.5em
In this paper several methods will be applied in an attempt to assist a users understanding of higher dimensional space. Users will be provided with a series of extensions to the visualisation of four dimensional geometry. Such methods include: viewing the object from other angles, attempts to visualise the object in its entirety spanning along the \(w\) axis, and abstractions of the rotation of an object in order to help interpret higher dimensional rotations.

\section{Motivation}

% first, motivate then state the general problem clearly. 

Three dimensional space is very neat. There are three degrees of translational freedom expressed by the three axes \(x\), \(y\) and \(z\). There are a further three degrees of rotational freedom that are most commonly expressed as rotations about each axis. 
This supposed tidiness has lead to misconceptions that are so heavily rooted in the average persons understanding of geometry, such that nearly every digital 3D system is built upon a mathematically impure foundation. 
%
In the 3D world, these misconceptions do not matter, and the mathematics is still sound. Quaternions, the most common method of controlling or interpreting rotation, is heavily used in gyroscopic devices, interactive digital 3D environments, animation and robotics. More abstract practices such as physics or mathematics, however, often need to consider geometry in higher dimensional spaces.
\vskip 0.5em
A variety of fields within science and engineering utilise the visualisation of higher dimensional spaces to tackle a variety of problems. To more intuitively understand a given problem defined in \(n\) dimensional space it is often suitable to reduce the dimensionality of the problem. However, when a problem is reduced to $\mathbb{R}^3$ or $\mathbb{R}^2$ it may become somewhat trivial. Visualisation of 4D objects can often server as the "bridge from the 'trivial cases' to the 'nontrivial cases'", \citep{zhou_visualization_1991}. Such problems that utilise the visualisation of four dimensional space include: Analysis of differential geometry, collision detection, analysis of 3D objects in motion, and scalar-fields in 3D space; among others \citep{zhou_visualization_1991}.
%\vskip 0.5em
%
%TODO: what is the benefit of trying to teach people about it?\\

\section{Aims}
\label{aims}

% wide range of 4 Dimensional shape. variety of ways to display. As such the usability of each representation will be experimentally validated in order to find the most intuitive and effective way to represent higher dimensional shapes. The accuracy of which the user can identify these properties and act accordingly will be measured against the representation being shown to them.

This paper aims to answer questions related to which representation of 4D space, presented as an extension to the 3D cross section, is the most effective in conveying the properties of four dimensional geometry to a user with limited experience. Which representation is the most effective at representing the surface of a 4D object? And which representation is more effective at conveying the rotational pose of an object in $\mathbb{R}^4$?
Furthermore, Does a users understanding and ability to manipulate 4D objects increase with practice? And can advantages of each representation be realised and digested by potentially inexperienced users?
\vskip 0.5em
As per the motivation for this project; an effective tutorial was compiled in order to explain the foundations of four dimensional geometry. A system to view and interact with 4D objects was developed in Unity, with the capability to showcase a wide variety of 4D shapes using ray marching. Research into intuitive methods of user interaction was explored, and a system to rotate an object without gimbal lock was employed.
\vskip 0.5em
This paper proposes several extensions to taking a 3D cross section of a four dimensional objects. Each extensions is designed to emphasise a different aspect of geometry. The project evaluation explores the effectiveness of each extension in assisting users to interpret higher dimensional spaces, and understand the surface, rotation and pose of a 4D object. 
%
Given a series of challenges, a study was conducted that allowed users to manipulate several 4D objects in order to evaluate their understanding of geometry, and compare their understanding against each representation of a 3D cross section. 
Metrics such as time taken, confidence and accuracy were measured, with each metric being applied to several tasks; with each task focusing on a different aspect of geometry in order to evaluate a users understanding of how a cross section of a four dimensional object changes under rotation.

%==================================================================================================================================
\chapter{Background}

\section{Representations of the Fourth Dimension}

There are many ways to represent the fourth dimension. Arguably the most intuitive understanding is that of a 3D cross section. As with how a sphere in $\mathbb{R}^3$ can be considered a stack of infinitely thin circles that vary in size from top to bottom, along the \(z\) axis; a four dimensional sphere can be considered as a stack of 3D spheres that vary in size as you move across the \(w\) axis.
\vskip 0.5em
The 3D cross section is limited given that only a slice of the shape can be seen at any given time. Stereographic projection can improve upon this by allowing a viewer to visualise as much of the shape as their field of view permits. Stereographic projection in $\mathbb{R}^3$ takes a 3D sphere and maps its geometry across a 2D plane. To project another shape, for example a cube, its geometry must be projected beforehand onto the surface of a sphere \citep{radiya-dixit_visualizing_2017}. Stereographic projection in $\mathbb{R}^4$ takes a spherical projection of a 4D object, and maps it across a 3D environment. A viewer can stand in the center of the 3D environment and observe the projected geometry. This approach of visualising 4D space is well suited to virtual reality, however it is complex to interpret in a meaningful way, and abstracting an understanding to lower dimensions is nontrivial.

\subsection{Extensions to the 3D Cross Section}

Through simple discussion with peers, a 3D cross section of a four dimensional object appears to be a far more intuitive concept to grasp compared against stereographic projection. 
%
The aims of the project are to investigate how one may extend a visualisation of a 4D object to provide a viewer with more information to assist their understanding of higher dimensional space. The 3D cross section of a 4D world appears to be the most appropriate visualisation, given it allows a user to abstract higher dimensional geometry to lower dimensional spaces in order to assist in their understanding of higher dimensional geometry.
\vskip 0.5em
An extension to a 3D cross section involves providing the viewer of the object with more information about the object they are exploring. Several such extensions have already been explored conceptually or even fully developed.
\vskip 0.5em
Showing several cross sections beside one another, where each cross section is offset by a multiple of distance $\delta$ along the \(w\) axis, is a simple means of trying to provide more information to a viewer about the shapes geometry. As shown in the 3D example \cref{fig:exti}: Several 2D circles taken at regular intervals along the \(z\) axis, that circularly increase and decrease in size, provides a viewer with enough information to deduce that the object being displayed is likely a 3D sphere.

\begin{figure}
  \centering
  \begin{subfigure}[b]{0.45\textwidth}
      \includegraphics[width=\textwidth]{images/extensions/timeline-delta.png}
      \caption{Several cross sections of 3D objects at $\delta$ intervals along the z axis}
      \label{fig:exti}
  \end{subfigure}
  %
  \begin{subfigure}[b]{0.45\textwidth}
      \includegraphics[width=\textwidth]{images/extensions/multi-view.png}
      \caption{Cross sections of a 3D cone and cylinder; where each cross section is taken along the specified plane.}
      \label{fig:exmv}
  \end{subfigure}   
  %
  \caption{Examples of extensions to a 2D cross section of 3D objects.
  }\label{fig:extensions}
\end{figure}

\citet{kageyama_visualization_2015} proposed such a system, displaying several cross sections of a 4D object along an ovular path, in order to try and provide a viewer with more information about the object. 
%
A far greater number of cross sections can be displayed along an ovular path through the use of vertical space, with comparison to a linear path. This allows for a more detailed view of the four dimensional object in its entirety.
%
Kageyama designed each cross section, as they move further away from the central slice, to decrease in size; avoiding potential confusion in conveying the idea that travelling across the fourth dimension wraps around, forming a circular path.
%
Scaling each cross section however, can produce some immediate confusion when first viewing an object. For example, taking several cross sections of a 4D cylinder extended along the \(w\) axis should produce several 3D spheres of the same size. Kageyama's visualisation, however, will have each of these 3D spheres decrease in size such that a user may interpret the shape as a 3D cross section of a 4D sphere, given it exhibits similar scaling behaviour. If a user were to move across the \(w\) axis, they could observe the lack of change in the size of the central 3D cross section and draw the correct conclusion that it is a cylinder.
Whilst the ovular display does provide a great deal of extra information to a viewer, it is limited by its obscurity given several objects may have identical cross sections.
%TODO: classify Kageyama's work
\vskip 0.5em
Another extension which arguably provides the user with more information about an object, is viewing said object from other angles. As shown in the 3D example \cref{fig:exmv}: take a cone that is extended upwards to a point along the \(y\) axis. From the top, a cross section of the object spanning the \(xz\) plane will produce a circle. However a cross section along either the \(xy\) or \(yz\) planes will appear as a triangle.
\vskip 0.5em
\textit{Polyvision} \citep{matsumoto_polyvision_2019} is a virtual reality system to view four dimensional objects from multiple angles to quickly and effectively understand the shape being interacted with.
%
\citet{matsumoto_polyvision_2019} represents 4D objects as wireframes, connecting each vertex of the object by an edge. This is possible when collapsing each vertex of the 4D object to the same three dimensional slice. This is often referred to as the "shadow" of an object. 
A user may view almost all of an object at once using this technique, in comparison to a single 3D slice; whilst potentially offering a more intuitive understanding, although perhaps less information, when compared to stereographic projection. 
The wireframe shadow has two main disadvantages. 
Firstly, curved, smooth objects are typically better represented by their surface, rather than a wireframe. 
Secondly, complex objects such as the 120-cell, contain hundreds to thousands of edges and vertices, rendering a chaotic image that may be hard to recognise. Viewing the surface of this object likely allows users a better understanding of the geometry.
%
With the goal of teaching others, \citet{matsumoto_polyvision_2019} restricts translation, rotation and scaling to the third dimension. Rotations in $\mathbb{R}^3$, from another perspective in $\mathbb{R}^4$ may produce a 4D rotation. Whilst the effects of 4D manipulation can be seen in this way, \textit{Polyvision} lacks the ability to directly manipulate an object in 4D space.
%TODO: classify Matsumoto's work

\section{Building a 4D Object}

Rendering three dimensional shapes on a 2D screen is an art that has evolved over time and ranges several disciplines. When \textit{Tron} released in 1982, computers were not powerful enough to develop and render triangle meshes in real time; as is the standard for 3D modelling nowadays. 
Similar films of that era, such as \textit{Dune} (1984) or \textit{Star Wars} (the Original Trilogy) (1977-1983) often used a mix of practical effects and physically modifying film, using techniques such as rotoscoping and double exposure. The team behind \textit{Tron}, however, opted to take advantage of machines to do some heavy lifting. In-spite of the technological limitations the team were able to build a system to combine and render simple but smooth primitive objects. They used a system called Ray Marching \citep{sheppard_tron_2010}.
\vskip 0.5em
Today, it is standard to use triangle meshes to build and even render complex models in real time; not just for film, but for real time interactive media such as video games.
A mesh consists of vertices, edges and faces. A vertex is a point on the surface of an object that edges connect to. A face is formed by a closed loop of edges. Generally, a face will be made up of three vertices and three edges, creating the most simple 2D shape: A triangle; which form a part of the surface of a 3D mesh.

\subsection{Mesh Based Rendering}

Both \citet{bosch_n-dimensional_2020} and \citet{tianli_4d_2018} have developed real time interactive systems which display four dimensional objects using mesh based rendering. As illustrated by \citet{tianli_4d_2018}, 4D shapes are made up of cells, similar to how a 3D mesh is made up of faces. As with a face in a 3D mesh being constructed of triangles (the most basic 2D shape), a 4D mesh is constructed of the most basic cell, a tetrahedron. A tetrahedron is made up of four triangles defined by faces, vertices and edges. The pentachoron, also known as a hyper-tetrahedron or a 5-cell, is the most primitive 4D object (besides potentially the hyper-sphere). The mesh of a pentachoron consists of 5 tetrahedral sub-meshes (cells). A sub-mesh in this instance refers to a 3D mesh used to build a 4D object, in the same way a 2D faces can build a 3D shape.
\vskip 0.5em
Mesh based rendering allows the creation of very complex higher dimensional objects. \citet{bosch_n-dimensional_2020} built a novel game engine implementing four dimensional rigid body dynamics, and several complex shapes, for example, a 4D klein bottle.
On the other hand, \citet{tianli_4d_2018} used the readily available Unity game engine to construct a hyper-cube and hyper-tetrahedron, demonstrating the flexibility of existing software intended for two and three dimensions.
\vskip 0.5em
There are two main drawbacks to mesh based rendering: The time taken to construct 4D objects, and the complexity of translating four dimensional geometry to 3D. 
%
Simple 4D Platonic solids \citep{parker_things_2014} such as the hyper-tetrahedron (5-cell), hyper-cube (8-cell) and hyper-octahedron (16-cell) are fairly straightforward. Developing complex shapes such as a the hyper-dodecahedron (120-cell) or the hyper-iscosahedron (600-cell) becomes a complex and time consuming task. 
This complexity only increase when trying to develop curve faced shapes such as a hyper-sphere, torus or cone, which are smooth. Smooth geometry generally requires hundreds of vertices as well as smooth surface shading that only add to computational load and development time.
\vskip 0.5em
In order to render a three dimensional slice of a four dimensional object, an algorithm must be employed such that a point along an edge that connects two vertices is found and connected, by edges, to all other points that sit along edges of the same object, all lying on the same four dimensional hyperplane. This is a fairly complex task, and only gets more complex when calculating what faces of the slice of the object in order to render a cohesive three dimensional slice. 
\citet{tianli_2d_2018} demonstrates how to find the cross section of an object and the problems associated with it.

\subsection{Ray Marching Shaders}

Ray march based rendering was initially developed due to limitations in real time rendering, as a way to combine easy to define primitive objects into more complex shapes. Despite advancements in\hfill rendering\hfill capabilities,\hfill allowing\hfill even\hfill low-end\hfill computers\hfill to\hfill render\hfill complex\hfill mesh\hfill based 
% Ray marching Diagrams
\begin{figure}[H]
  \centering
  \begin{subfigure}[b]{0.45\textwidth}
      \includegraphics[width=\textwidth]{images/raymarching/raymarch_ai.png}
      \caption{Ray marching to produce an image}
      \label{fig:rmcast}
  \end{subfigure}
  %
  \begin{subfigure}[b]{0.45\textwidth}
      \includegraphics[width=\textwidth]{images/raymarching/algorithm_ai.png}
      \caption{Ray marching algorithm}
      \label{fig:rmalg}
  \end{subfigure}   
  %
  \caption{Ray marching. \subref{fig:rmcast} shows how each pixel of an image is coloured by casting a ray from the camera in the direction of the pixel and reading the surface of any defined geometry. 
  \subref{fig:rmalg} shows the process of a single ray marching towards a surface, given a an origin point and a direction as described in \cref{alg:raymarch}.
  }\label{fig:raymarch}
\end{figure}
%
% Ray marching Algorithm
\begin{algorithm}[H]
  \DontPrintSemicolon
  
  \KwData{\\
    \quad $r_o$ the origin of a ray.\;
    \quad $r_d$ the direction of a ray.\;
    \quad $MAX\_STEPS$ the maximum number of iterations.\;
    \quad $MAX\_DIST$ the maximum distance from the ray origin.\;
    \quad $SURF\_DIST$ the smallest distance from a surface before deciding not to step any further.\;
    \quad $SDF(p)$ given a point $p$ along the ray, return the distance to the nearest surface.\;
  }
  \KwResult{\\
    \quad $ d_o $ The distance from the ray origin along the ray path.
  }
  \Begin{
      $ d_o \longleftarrow 0 $\;
      $ d_s \longleftarrow \infty $\;
      \For{$ i < MAX\_STEPS $}
      {
          $ p \longleftarrow r_o + d_o \cdot r_d$\;
          $ d_s \longleftarrow SDF(p) $\;
          $ d_o \longleftarrow d_s + d_o $\;
          \If{$d_s < SURF\_DIST \textbf{ or } d_o > MAX\_DIST$}
          {
              break\;
          }
      }
  }
\caption{The ray marching algorithm}\label{alg:raymarch}
\end{algorithm}
%
geometry in real time, ray marching has not lost its place in the world. 
Whilst ray marching has often thought to have evolved into ray tracing, the foundation of photorealistic rendering, signed distance fields (SDFs), the core of ray marching, are still heavily used in volumetric geometry, meta-ball geometry, collision detection and ray marched shaders.
An SDF is a function that describes a signed distance to a surface relative to a point in space. \citet{quilez_distance_nodate} lists several SDFs for primitive objects as well as functions that can be applied to them.
\vskip 0.5em
Ray marching (\cref{alg:raymarch}, \cref{fig:raymarch}) is the processes of calculating the colour of each pixel on a screen by casting a ray from an origin point in the direction of a pixel. The pixel is coloured based on the distance to a mathematically defined geometric surface. Given an origin point and a direction, the algorithm takes the distance to the nearest surface. It then marches forward by that distance to map out the surface detail. \citep{the_art_of_code_ray_2018}.
\vskip 0.5em
%
Whilst less intuitive than mesh based rendering, there are active communities striving to build interesting and complex geometry with ray marching. \textit{Shadertoy} \citep{quilez_shadertoy_2013} is a web based platform allowing anyone to create and experiment with shader based geometry.
\vskip 0.5em
A significant advantage over mesh based rendering is the ability to render a 3D cross section of a 4D object with minimal effort. The SDF of a 4D object taken over three dimensional space will yield the cross section of the object in a given hyper plane along the \(w\) axis.
It is not novel to ray march over primitive 4D objects such as the hyper cube or hyper sphere. Often, primitive SDFs taken over $\mathbb{R}^3$ can be easily extended to $\mathbb{R}^4$; and this is the case for many of the SDFs developed by \citet{quilez_distance_nodate}. Other 4D geometry on the other hand needed to be derived from scratch. 

\section{Rotating a 4D Object}

In $\mathbb{R}^3$ there are three degrees of rotational freedom. As there are three axes, the method of rotating an object has commonly been considered as rotating about an axis. 
In $\mathbb{R}^4$ there are six degrees of rotational freedom, despite there only being four axes. Instead, rotation is considered about a plane formed by two axes. 
The six planes of rotation in $\mathbb{R}^4$ are \(xy\), \(xz\), \(yz\), \(xw\), \(yw\) and \(zw\).

\subsection{The Problems with Rotation}

Rotating an object in $\mathbb{R}^2$ is somewhat trivial. Given a vector $v_{xy}$ rotating an angle $\theta$ about an origin point within the \(xy\) plane, the vector will follow a circular path dictated by the following 2D rotation matrix:
% 2D Rotation Matrix
\begin{equation}
    v_{xy}' = v_{xy}\begin{bmatrix}
      cos \theta & - sin \theta \\
      sin \theta & cos \theta
    \end{bmatrix},
\end{equation}
%
Rotating an object in a space greater than two dimensions immediately becomes a nontrivial problem due to its non-commutativity. In higher dimensions, rotation matrices can be composed into a homogeneous rotation matrix. Multiplying a vector with a such a matrix will rotate a vector, but doing so will likely encounter gimbal lock. Gimbal lock occurs when considering each plane of rotation independent to one another. As a result, if a particular plane becomes parallel to another, a degree of rotation is lost and the vector will not rotate as expected.
\vskip 0.5em
Introducing the quaternion; an extension of the complex number system. A quaternion has 4 components: \(x\), \(y\) and \(z\) which describe the axis of rotation, and \(w\) which describes the amount of rotation. Quaternions do not suffer from gimbal lock and can be applied to each other to perform several rotations in series.
\vskip 0.5em
Quaternions have a problem: They consider rotations as a rotation about an axis. As discussed by \citet{bosch_lets_nodate}, axial rotations are not appropriate as a generalised method of rotation across dimensions. For example, you would not consider a 2D object rotating within two dimensions as rotating about the \(z\) axis. It makes far more sense to stay within $\mathbb{R}^2$ and rotate about the \(xy\) plane.

\subsection{Geometric Algebra and The Rotor}
\label{ga_and_rotor}

Geometric Algebra (or Clifford Algebra) is a field of mathematics describing vector space. Vector space is populated by multivectors, graded by their vector components. Multivectors are defined by their associative, distributive and anti-commutative properties \citep{baker_maths_nodate}.
A grade 0 multivector is a scalar number. a grade 1 multivector is just a vector. Grade 2 multivectors are known as bivectors, which build the foundation for the rotor. A trivector is a grade 3 multivector forming a parallelepiped from three vectors. Finally in $\mathbb{R}^4$ a grade 4 multivector is known as a pseudo-scalar.
\vskip 0.5em
A bivector $b_{ab}$ is made up of two vectors \(a\) and \(b\). Its two vector components define its orientation in space. The bivector is also defined by two important properties: The direction of rotation, from \(a\) to \(b\), and the area of the parallelogram formed by its two vector components as illustrated by \citet{slehar_clifford_2014}. A bivector in the reverse direction, i.e from \(b\) to \(a\) fulfills the anti-commutative property such that $b_{ba} = -b_{ab}$. 
% TODO: Wedge Product similar to Cross Product
\vskip 0.5em
As mentioned above, a rotation should be considered as a rotation about a plane. A bivector defines the plane for a vector to rotate about. As demonstrated by \citet{mathoma_geometric_2017}, a rotor can rotate a vector following the principle that a double reflection forms a rotation \citep{mathoma_geometric_2016-2}.
\vskip 0.5em
In a given vector space greater than $\mathbb{R}^2$, a multivector greater than grade 0 can be projected onto the vector space basis blades. The basis blades of a grade 2 multivector are the planes formed by two perpendicular axes. The \(xy\) blade is often referred to as $e_x \wedge e_y$ or $e_{xy}$ or sometimes $e_{01}$. Therefore a bivector in $\mathbb{R}^3$ can be decomposed into three projections onto the $e_{xy}$, $e_{xz}$ and $e_{yz}$ planes. A bivector in $\mathbb{R}^4$ can be decomposed into six elements.
The outer (wedge) product of two vectors is used to calculate the area of a bivector, and is used to calculate the area of its projections.
\vskip 0.5em
It is possible to multiply multivectors using the geometric product; a combination of the inner and outer product. Multiplying a vector \(v\) by a rotor \(R\) and it's reverse \(R^\dagger\) will rotate vector about the bivector component of the rotor. Order matters here.
%
\begin{equation}
  \label{eq:sandwich_a}
    v' = R v R^\dagger,
\end{equation}
%
Rotors can also be multiplied using the geometric product. This will produce a new rotor. Therefore two rotors; $R_a$ and $R_b$, can be composed as shown in \cref{eq:sandwich_b} to rotate a vector \(v\) and produce a rotated vector \(v'\).
%
\begin{equation}
  \label{eq:sandwich_b}
  v' = R_a R_b v R_a^{\dagger} R_b^{\dagger}
   = (R_a R_b) v (R_a R_b)^{\dagger}
   = R_{ab}^{} v R_{ab}^{\dagger}
\end{equation}
%
The angle of rotation is dictated by a scalar component of the rotor, similar to the \(w\) component of a quaternion. 
As shown by \citep{bosch_code_nodate}, the quaternion and the rotor are very similar in concept. The rotor, unlike the quaternion, has the advantage of not leaving the dimensionality of the vector space in order to rotate the vector, allowing it to be used in \(n\) dimensions.

\section{Interaction and Direct Manipulation}
\label{background_rotation}

\subsection{Methods of Interaction in 3D}

\subsection*{Common Approaches}

Intuitive manipulation of virtual objects in three dimensions is challenging. Excluding mixed reality, generally we can only interact with geometry through a 2D interface.
%
One common method of rotating a 3D object through a 2D screen is with the use of swiping. Swipe-based rotations are very common on touch screen devices, utilising multi-touch as a secondary input to switch dimensions. 
Assuming the $z$ axis protrudes from the screen, swiping left or right will rotate about the $xz$ plane, up and down will rotate about the $yz$ plane. Two fingers rotating clockwise or anti-clockwise will perform a rotation about the $xy$ plane. 
Swipe-based rotation is limited to performing rotations only relative to the global axes, opposed to the local axes of a rotated object on screen. As a result, fine tuned manipulation is somewhat challenging, hence it is not common in professional 3D development software.
\vskip 0.5em
Alternatively, the most common method of rotating an object takes rotations relative to a local axis. This local axis can be assigned to world space, or rotate objects relative to their real time pose. The method of rotation, despite its popularity, appears unnamed. It will be referred to as a grab ball. The grab ball is made up of 3 arcs. An arc can be selected, restricting the plane of rotation parallel to the arc. The user may drag the mouse to rotate the object, and grab ball, along this plane of rotation. As the grab ball rotates with the object, the user is in control of the objects rotation relative to its local axis at all times. 
The grab ball provides an efficient method of rotation, but is implemented in different ways throughout various software. For example, \textit{Blender} allows the user to rotate whilst moving the cursor along the path of the arc. \textit{Unity} however requires the user to move the mouse along the path tangent to the arc.

\subsection*{Novel Hardware-based Approaches}

Whilst this projects implementation for manipulating geometry is software focused, it is worth noting the research into hardware based solutions. The \textit{Rockin'Mouse} \citep{balakrishnan_rockinmouse_1997} is an example of a hardware centered approach in assisting users with 3D interaction. 
A regular mouse allows a user to control two translational degrees of freedom (DoF). As a result, a method of switching between dimensions is required in order to fully manipulate geometry in 3D.
The \textit{Rockin'Mouse} is a four DoF input device that can be tilted in two DoF. Being in control of four DoF simultaneously, allows users to manipulate geometry in all three dimensions without the need for a secondary input. Results indicate that this hardware allows users to manipulate geometry in 3D 30\% faster than with the use of a traditional mouse. 
The main drawbacks of hardware focused methods of interaction is the expense and lack of accessibility.

\subsection*{Novel Software-based Approaches}

Given an object encased in a sphere, a user may roll the sphere to rotate the object inside. The virtual sphere \citep{chen_study_1988} allows users to roll the object by dragging their mouse across the surface of the surrounding sphere. dragging the mouse outside of the sphere will rotate the object about the $xy$ plane; the screen the object is being viewed through. This method is similar to swiping, mentioned earlier, but enables the user to control all three degrees of rotational freedom without the need for a secondary input to switch between planes of rotation.
\vskip 0.5em
Hysteresis, or path dependance, is when the resulting pose when dragging a mouse from point $A$ to point $B$ may be different depending on the path taken. The virtual sphere exhibits hysteresis, and as such a rotation cannot be undone by reversing the previous action.
Arcball \citep{shoemake_arcball_1994} is similar to the virtual sphere, in that the cursor of a mouse is projected onto and dragged across an on-screen sphere. 
The major difference between the virtual sphere and arcball, is that arcball does not exhibit hysteresis. This is accomplished through two properties:
The system utilises the double coverage property of quaternions, such that dragging from either side of the sphere, $180^{\circ}$ apart, will complete a full $360^{\circ}$ rotation.
Arcball consistently compares the initial point $A$ to the updated mouse position $B$ in a single drag, producing one arc of rotation. Combined with the double coverage, any path from $A$ to $B$ will result in the same rotation.
\vskip 0.5em
According to \citet{hinckley_usability_1997}, there is no evidence that the arcball may be better than the virtual sphere. However, users of the two mechanics generally report the arcball to be more responsive and allow for more control. 
On the other hand, many users enjoy the virtual spheres slower movement as it emulates the feeling of "pushing" the object around.

\subsection{Methods of Interaction in 4D}

Direct manipulation of 4D geometry is immediately a more complex problem given double the number of planes of rotation. 
\citet{shoemake_arcball_1994} remarks that a pair of arcballs can be used to rotate an object in four dimensions. 
\citep{hanson_rolling_1992} also proposes a similar approach, taking advantage of a virtual sphere to rotate in 4D.
\vskip 0.5em
A primitive solution proposed by \citet{kageyama_keyboard-based_2005} explores the idea of using keyboard inputs to rotate an object in all 6 DoF. This system allows users to compose rotation matrices for incremental control over how an object rotates. As the system uses rotation matrices, it is at risk of gimbal lock. Key presses are also discrete, limiting a users precision. A more desireable approach may be to utilise a mouse for a more continuous spectrum of rotation, with an optional incremental feature, as is standard with most 3D software.

\pagebreak
\citet{yan_multitouching_2012} takes advantage of multi-touch screen devices, and the different gestures that can be accomplished with two or more fingers. Multi-touch presents itself as an easier and more intuitive secondary input opposed to the use of a keyboard, where different gestures refer to different rotations.

\section{Teaching and Evaluation}
\label{teaching_and_eval}

In order to evaluate the effectiveness of each extension to a 3D cross section of a 4D object, a participant should have an understanding of what four dimensional geometry is, and how it behaves.
For this investigation, it was a priority to ensure this complex mathematical topic can be well communicated to individuals with little-to-no experience of higher dimensional space, prior to conducting the experiment. \textit{The van Hiele Model of Geometric Thinking}, \citep{safrankova_van_2012}, theorises that their are five levels of understanding geometry, where a student will progress from one level to the next: Visualisation, Analysis, Abstraction, Deduction and Rigor, numbered 0 to 4 respectively.
Level 0 focuses on the identification and recognition of geometry using simple language. The properties that define a geometry need not be identified.
Level 1: students begin basic analysis and identification of geometry, without a need for proofs.
Level 2: students create meaningful definitions and are able to justify and reason their understanding of geometry.
Level 3: students are able to provide deductive geometry proofs, showing their understanding of formal definitions and theorems.
Level 4: students have an understanding of several proofs and can comprehend Euclidean and non-Euclidean geometry.
\vskip 0.5em
\citet{safrankova_van_2012} outlines the five stages of the learning process to comprehensively cover the material and reaffirm a students understanding; as outlined in the van Hiele model.
\textit{Information inquiry} is where students receive the material and discover the structure of the information they are handling. At this stage a teacher should use familiar language to help a student relate what they already understand to the new material.
\textit{Guided or directed orientation} deals with the exploration of relationships within the material. A teacher may suggest activities enabling students to recognise the properties of a new concept. Discussion is encouraged between the student and the teacher to assist in discovering relationships between properties of the material.
\textit{Explanation or Explication}: Students formulate what they have discovered. New terminology is introduced whilst the student shares their thoughts on the relationships discovered. Here a teacher can ensure the correct terminology is being used.
The \textit{Free orientation} stage allows for students to solve more complex tasks independently to master the network of relationships within the content. A student may develop their understanding of the properties of geometry as well as develop their understanding of the material in a variety of scenarios.
Finally, \textit{Integration} involves the student summarising what they have learned. No new material is presented in this stage.
\vskip 0.5em
For the purposes of this experiment, only levels 0 to 2 of \textit{The van Hiele Model of Geometric Thinking} will be explored. A rule of the model is that a student may not progress to level \(N\) without having first tackled level $N-1$. 
In order to best evaluate the effectiveness of an extension to the 3D cross section of a 4D object, a participant of the investigation should understand the geometry they are working with.
Unfortunately, given the limited time to conduct the investigation, and that of an individual experiment, participants would not be able to sufficiently progress through each level, whilst also covering each of the five stages of the learning process. 
To provide a participant with the best possible foundations for understanding four dimensions, tutorials and question and answer sessions before and after each stage in the experiment were conducted. The experiment was designed around the structure of the five stage learning process as is expanded upon in the experimental design section (\cref{experimental_design}) of this paper.

%==================================================================================================================================
\chapter{Analysis and Requirements}

\section{Problem Specification}

The core of this project focuses on the development of a system capable of rendering several different types of four dimensional objects, and be able to view these objects through a series of extensions to the 3D cross section in order to evaluate their effectiveness in teaching potentially inexperienced users about complex geometry.
\vskip 0.5em
For a successful investigation, a focus was placed on the visualisation of 4D geometry, as well as how users learn and interpret this geometry. It is important that the experiment was to be clear and concise. Both quantitative and qualitative metrics were obtained. To properly evaluate each representations of an objects cross section, the experiment required tests probing a participant on the surface, behaviour under rotation and identification of the rotational pose of an object in $\mathbb{R}^4$.

\section{Limitations}

The scope of the project was limited by two main factors: The time that can be spent on development, and the quantity to quality ratio of experimentation. 
The project is primarily separated into three components: Research, development and experimentation. The development phase took the most time with so many areas for exploration. Such areas include the creation, stable rotation, and manipulation of 4D geometry. To evaluate the effectiveness of the representations that need to be developed however, plenty of time needed to be put aside to plan and run appropriate experiments.
Experimentation is, more often than not, limited by the number of participants that choose to be involved. To encourage the greatest number of potential participants to enroll in the experiment, the time commitment and effort cannot be so great that it deters them. Alongside the conscious effort to sign up, the experiment cannot run for such a period of time that it may effect a participants performance. As such, the amount of data that can be collected in one sitting was to be maximised within a limited time frame.

\section{The Framework}
\label{requirements_framework}

The project was developed in the Unity game engine using ray marching shaders. Unity is readily available to anyone for free; and allows for quick and simple application deployment for web based hosting using WebGL and HTML5. 
Given the COVID-19 pandemic at the time of the experiment, online hosting was an important consideration to allow for a more accessible experiment in a world where people are having to self isolate. Not only does this allow for a participants safety, but the potential size of the audience can be increased. Online hosting reduces the commitment a participant has to make, making the experiment more appealing. Time to commute and costs of travel that potential participants would otherwise have to make, now no longer factor into the considerations made by a potential participant when signing up for the experiment.
\vskip 0.5em
Ray marching was used rather than mesh based rendering given its comparative ease. Several 4D shapes can be written fairly quickly using ray marching. Although complex geometry with defined faces, such as the 120-cell is a struggle to write using ray marching, render curved geometry using mesh based rendering requires the development of a smooth shading rendering effect. 
Moreover, the experiment only intended to test users with 4D primitive objects given they are easier to understand and relate to three dimensions. 
Furthermore, implementing a rendering of the 3D cross section of a 4D object is comparatively trivial using ray marching. To render the three dimensional cross section of a 4D mesh is yet another system to develop that would require more time and research. 
Generally, ray marching is more suitable to this project in exploring primitive geometry in $\mathbb{R}^4$, and allows for more time to be spent on the research and development of stable rotation and manipulation of 4D geometry, and the creation of a cohesive investigation.

\section{Prioritisation of Requirements Using MoSCoW}

MoSCoW is a prioritisation technique used in project planning. The purpose of MoSCoW is to separate the requirements of a project into four levels of priority: Must have, Should have, Could have and Won't have this time. This process may be revisited several times during a projects development lifecycle; different requirements are often re-prioritised based on project progress or a change in direction.

\subsection*{Must Have}

The following requirements are necessary in order to conduct a successful evaluation and were compiled and refined throughout the projects development:

A system must be developed that is capable of rendering 4D shapes. As such, several 4D shapes must be created. 
In order to test a persons understanding, of the 4D shapes that are to be developed, they must not all be immediately distinguishable from one another. For example, a hyper-cube and a hyper-sphere will never look similar to each other, whereas, the 3D cross section of a 4D hyper-cone in a particular pose will look identical to the 3D cross section of a 4D hyper-sphere.
\vskip 0.5em
The aims of the project focus on the development of several extensions to the 3D cross section in order to find what extensions are better for conveying the complexities of 4D geometry to potentially novice users. Therefore, several extensions to the 3D cross section of four dimensional space should be developed. The extensions to the 3D cross section may take inspiration from the literature mentioned earlier, and attempt to improve upon or emphasise the components of their work that are relevant to this investigation.
\vskip 0.5em
To distinguish the faces of shapes, the objects will need to be coloured such that given two objects in a different pose, both objects can be distinguished from one another even if their surface shape appears identical. 
\vskip 0.5em
In order to prepare participants for the experiment, an introductory tutorial video will need to be assembled to teach and explain to them about the complexities and features of the fourth dimension. This tutorial video must cover the behaviour of geometry in $\mathbb{R}^4$, with appropriate references to the similarities when reducing three dimensional space to a two dimensional cross section. 
Moreover, the video must explain rotation in four dimensions, as well as an explanation for the behaviour that occurs when rotating an object outside of the dimensions it is being viewed within. The video must have relevant diagrams and animations to appropriately depict the behaviour of 4D shapes in such a way that is related to the following experiment.

\pagebreak

Before running the experiments, the tasks must be completed and evaluated several times by myself, and complimented by some preliminary research with a small group of peers to ensure the functionality of the system is as expected, and any restraints such as time limits are within acceptable bounds.
\vskip 0.5em
Finally the experiment must have multiple stages of testing to evaluate a persons understanding of the several aspects of geometry. The experiment must not last such a long time that it affects the participants performance. To appropriately evaluate a persons understanding alongside the effectiveness of a representation, qualitative data must be collected from the participant, about their understanding, including open and closed questions.

\subsection*{Should Have}

Whilst not a necessity, the following requirements would enhance the investigation, allowing the further exploration of the four dimensional world.

"Free orientation", as stated by \citet{safrankova_van_2012}, is an important aspect in a students learning and understanding of the definition and behaviour of geometry. In order for a participant to master the complexities of geometry in $\mathbb{R}^4$ they should be able to handle 4D objects directly.
Evaluating a participants understanding of a shape, its surface and its behaviour under rotation can be conducted without directly interacting with or manipulating an object; however a system should be developed allowing a participant to directly interact with 4D objects in order to perceive, first hand, the effect they have on the cross section o the geometry.
For direct manipulation in four dimensions, a 4D Rotor must be implemented to allow for stable interaction, without fear of gimbal lock.
\vskip 0.5em
Following the implementation of a system to freely rotate 4D geometry, a challenge should be implemented evaluating a participants understanding of the geometry through the use of the manipulation of objects on screen.

\subsection*{Could Have}

Given the limitations, although it would be nice to include, the following requirements are the lowest priority. The requirements will be explored, but are not necessary to conduct the investigation and will likely not be refined to a satisfactory degree.

It would be desirable to implement a series of tools for manipulation, allowing for intuitive interaction of 4D geometry. Such methods of interaction will be experimented with. The experiments, however, will only implement one method of rotation for the experiment, given the investigation focuses on the ways to enhance the cross section of 4D space, rather than how to manipulate these objects. Therefore, it is of minimal priority to develop several methods of rotation, although during the research and development phase, several methods of interaction will be explored.

%==================================================================================================================================
\chapter{Design}

Given this investigation revolves around a participants understanding of complex geometry, it is important that they are familiar with the behaviour of this geometry prior to completing the main portion of the experiment:
Each extension to the 3D cross section will be evaluated against a series of tasks a user must complete. Prior to this phase, the user will be trained on the complexities of the fourth dimension. Elements will be taken from the \textit{van Hiele model of geometric thinking} as discussed in \cref{teaching_and_eval}. 
%
The different portions of the experiment heavily encouraged discussion with the teacher/observer in order to ensure the best understanding a participant may have of four dimensions prior to and during the experiment.

\section{Tutorial}
\label{tutorial}

A brief discussion was conducted with each participant following their introduction to the experiment and what the experiment would entail. This discussion focused around a participants prior knowledge with the concepts of 4D.
As per the first stage of van Hiele's requirements for teaching, \textit{information inquiry}, students are to receive the material and discover the structure of the geometry presented in this stage. This introduction should use familiar, well-known and understood language.
The material received by the students at this stage was compiled in the form of a video tutorial, linked here: 
\url{https://www.youtube.com/watch?v=fhnhK7w67_s}
\vskip 0.5em
The tutorial was structured such that the world of four dimensions could be built upon piece by piece in hopes that students would better digest each component of $\mathbb{R}^4$ in turn without feeling too overwhelmed.
To begin with, the concept of a fourth perpendicular axis was introduced, with emphasis that this could not be visualised, and instead a method of viewing 4D geometry would be with the use of a 3D cross section. 
The 2D cross sections of some primitive 3D shapes, namely the hyper-sphere and a hyper-cube, were showcased. 
To complement the behaviour of a shapes cross section, the geometry of a hyper-sphere and a hyper-cube were described independent to their cross sections.
\vskip 0.5em
The rotation of 4D geometry is a more complex subject. As such, the rotation was broken down into several stages.
Rotation in \(n\) dimensions must be considered a planar rotation, opposed to axial rotations as most people are used to. 
Planar rotations are first introduced in 3D and were equated to the axial rotations to assist in a learners understanding.
To emphasise how planar rotations work in \(n\) dimensions, a 2D cross section of a 3D object is first rotated within the two dimensions of a slice in 3D space. This showcases that an object rotating within a cross section does not change size or shape. On the other hand, a 2D slice of a 3D object, rotating in three dimensions  (a rotation involving the $z$ axis) will change size and shape. The parallels are then drawn between the 3D cross section of a 4D object: The 3D cross section will not change size or shape for any rotation within three dimensions, however it will if rotating in four dimensions (a rotation involving the $w$ axis).
%\citep{subbiani_4_2022}

\section{Experiment}
\label{experimental_design}

%discuss video - explanation or explication - integration
An informal discussion took place after the tutorial video to elaborate on the participants understanding. This discussion would utilise the \textit{explanation or explication} and \textit{integration} phases of the learning process; where a student is asked to formulate what they have learned, and share their opinions on the relationships they have discovered. Here the teacher may correct terminology. Towards the end of the discussion, the participant would summarise what they have learned ensuring adequate preparation for the coming experiment.
\vskip 0.5em
Given the limited time to conduct an experiment, the remainder of the experiment took guidance from the \textit{free orientation} and \textit{guided or directed orientation} stages of van Hiele's learning process, effectively merging them into a single orientation phase.  
%play with a 4D shape, get the hang of controls - free orientation
Participants were provided with a 4D hypercube, and a summary of the controls to manipulate the shape. The participant was allowed to spend time observing how the shape may change when undergoing different rotations, as well as how the shape may change when moving it through the hyper plane. 
Informal tasks were proposed to the participants allowing them to connect relationships of the geometry. An example of such a task included: Rotating the shape with the use of a 4D rotation such that the colours of two opposing faces of the 3D cross section switch sides of the object. Here participants may learn basic properties of rotations in $\mathbb{R}^4$.
\vskip 0.5em
%testing - guided or directed orientation
Of the developed extensions to the 3D cross section of four dimensional space, different extensions may have different strengths and weaknesses. Some extensions may excel in describing the surface geometry of an object, whilst others may better convey the rotation of an object in $\mathbb{R}^4$. Therefore the main portion of the experiment was broken down into a series of three tasks, repeated for each representation. Each of the three tasks focuses on a different aspect of geometry: understanding the shape of a 4D object, understanding the rotation of a 4D object, and the ability to manipulate a 4D object.
First, the participant was be tested on their understanding of the surface of a shape. Given a cross section of a 4D object, the participant should be able to identify the shape on screen.
Second, the participant was tested on their understanding of any rotations a 4D object may undergo. Given a 4D object under continuous rotation, the participant should be able to identify the active planes of rotation.
Finally, the participant was tested on their ability to manipulate 4D geometry. Given a second object in a random pose, the participant is tasked with matching the primary objects orientation, with that of the secondary object. The randomly orientated object is only randomly oriented along 4D planes of rotation, allowing a user to manipulate both shapes simultaneously in 3D to view all sides of the objects in question.

%requirements for testing
% - be able to understand the shapes
% - be able to interpret the rotation of a shapes
% - be able to manipulate a shape

%requirements for teaching
% - match up with van-hiele model

% information inquiry - VIDEO
% - students receive information and discover structure
% - well known language

%guided or directed orientation - Experiment
% - deal with tasks to explore relationships
% - teacher that suggests activities enabling students to recognise %properties of a new concept
% - relationships are discovered and discussed
%   - encourage discussion

%explanation or explication - DISCUSSION AFTER VIDEO
% - student formulate what they have discovered and new terminology is introduced
% - share opinion on relationships discovered
%   - encourage discussion
% - teacher ensures correct terminology - more useful than familiarity with concept

%free orientation - MOST IMPORTANT FOR THIS PROJECT
% - student solves more complex tasks independently
% - master network of relationships in material
% - know properties but develop understanding of relationships in various situations

%integration - DISCUSSION BETWEEN VIDEO AND EXPERIMENT
% - student summarises what they have learnt
% - do not present new material in this phase
% - summary of what has been learned

\section{Interaction}

To intuitively rotate an object in all six degrees of freedom, the method of interaction should be familiar to the user. 
A common human computer interaction technique for intuitive navigation of a user interface is to have an action made by the user be analogous to a real world action. For example, swiping across the screen to move a digital object aside, is designed to mimic moving a real object in the same way. 
The same methodology was employed, allowing the user to interact with an object by swiping in the direction of rotation. The 2D screen limits the types of gestures that can be accomplished when manipulating an object in three or four dimensions. Touch screens overcome this limitation through multi-touch. Alternatively, as used in this project, a keyboard used in combination with a mouse can allow for alternative interactions that specify or limit the dimensions being used.
To assist a user in rotating an object, a set of $x$, $y$ and $z$ axes were displayed in the corner of the screen so a user may infer which planes of rotation they may choose to limit.
As a result, an intuitive system has been developed, allowing users manipulate objects in any of the six planes of rotation through the 2D user interface. This is expanded upon more in \cref{interaction}.

%==================================================================================================================================
\chapter{Implementation}

\noindent
\begin{minipage}[c]{0.45\linewidth}
  To conduct the investigation, four main components had to be developed (\cref{fig:components}): Building and rendering 4D shapes, rotating and manipulating these shapes, building and running the experiment, and collecting and analysing the data from the experiments.
  There would be no project without the ability to render 4D shapes, so of course this was developed first. The experimental tasks were built up alongside the development of the rotor, and of course the rotor was required in order to manipulate the 4D shapes. After the experiment was assembled, data analysis tools could be developed independently, as experiments were run.
\end{minipage} 
\hspace{0.8cm}
\begin{minipage}[c]{0.4\linewidth}
  \begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{images/Implementation Schema.drawio.png}
  \caption{Project Component Diagram}
  \label{fig:components}
  \end{figure}
\end{minipage}

\section{Building 4D Objects With Ray Marching}

As stated in \cref{requirements_framework}, ray marching shaders in Unity were used to develop and render three dimensional cross sections of four dimensional objects.
Ray marching over signed distance functions in Unity is not an uncommon topic within art and game development communities.
To render a ray marching shader, a material utilising the ray marched shader must be applied to an object, such as a plane. The scene defined within the shader will be rendered onto the object.
Before implementing a system to render four dimensional objects, a foundation was layed in the form of a three dimensional ray marcher in Unity \citep{the_art_of_code_writing_2019}. 
The ray marching algorithm (\cref{alg:raymarch}) casts a ray from an origin pointer towards a pixel on the screen, to determine how to colour this pixel. The algorithm takes a signed distance function (SDF) which returns the distance from a point \(p\) along the ray to the surface relative to an origin point. 
To summarise the basics of SDFs, \cref{lst:sdSphere} shows a signed distance function written in GLSL for a \textbf{sphere} in $\mathbb{R}^3$ with radius \(r\). 
The center of the sphere is offset from the origin. To interpret this, the opposing translation is applied to the point \(p\), along the ray. Using \(p\), the distance to the surface is calculated. Subtracting the radius from the distance to the center of the object defines the surface of the sphere about its center.
\vskip 0.5em
%
\begin{lstlisting}[language=glsl, caption={The signed distance function for a sphere in $\mathbb{R}^3$ with a center at $(1,0,0)$, and radius $r$}, label=lst:sdSphere]
  float sdSphere( float3 p, float r )
  {
      p -= float3(1,0,0);
      return length(p)-r;
  }
\end{lstlisting}

The 3D ray marching shader written in Unity defines two vectors describing the ray origin and the hit position of the ray. These vectors are used to define the ray origin and ray direction for each pixel, to calculate what the shader should render.
When extending the ray marcher to four dimensions, the majority of the process was enabling the algorithm and its components, such as the SDF, to take 4D vectors (\texttt{float4}), rather than a 3D (\texttt{float3}). Given the components of the shader describing the ray origin and direction existed along the same slice of four dimensions, only a single 3D slice of the four dimensional space was taken and rendered, giving us the 3D cross section.
\vskip 0.5em
With the standard ray marcher implemented the shader can only interpret whether a ray hits a surface or not. The only information of a 3D shape that can be gathered from this binary value will be its 2D shadow. In order to render a 3D component of the object, we need light and shadows. 
Two basic methods of shading include angle dependant light falloff - lambertian diffuse elimination - and shadows cast by other objects obstructing a light source \cref{lst:rm_light}. 
A surface normal is a vector that is perpendicular to a point on the surface and can be used to measure the angle of the surface relative to another vector. 
Using the surface normal an lambertian diffuse elimination can be implemented such that a surfaces light value will be lower if the difference between the surface normal and the vector to the light source is higher.
A shadow cast by on to a surface can be taken by ray marching from a surface in the direction of the light source to check if there is another surface obstructing the path. If there is, the surfaces light value can be lowered.

\begin{lstlisting}[language=glsl, caption={Given a light position \texttt{lightPos}, shade the surface based on the fall off angle and cast a shadow, if a surface is obstructing another surface from the light source}, label=lst:rm_light]
float4 GetNormal(float4 p)
{
    float2 e = float2(0.01, 0);

    float4 n = GetDist(p) - float4( 
        GetDist(p-e.xyyy),
        GetDist(p-e.yxyy),
        GetDist(p-e.yyxy),
        GetDist(p-e.yyyx)
    );
    return normalize(n);
}

float GetLight(float4 p, float4 lightPos)
{
    //angle dependant fall off
    float4 lv = normalize(lightPos-p);
    float4 n  = GetNormal(p);
    float  light  = clamp(dot(n,lv), 0., 1.);

    //shadow
    float4 so = p + n * SURF_DIST * 2.; //shadow origin
    float4 sd = normalize(lightPos-so); //light direction
    float d = Raymarch(so, sd);
    if( d < length(lightPos-p) ) light *= 0.1;

    return light;
}
\end{lstlisting}

\subsection{Derivation of 4D Shapes}

Ray marching excels at creating infinitely complex shapes, such as high dimensional fractals. 
Participants of the experiment may have little to no experience with higher dimensional geometry. To effectively evaluate each extension to the 3D cross section, the participant needs to understand the information they are seeing on screen. The best way to convey complex ideas is with simple examples; ergo, using geometric primitives, rather than complex geometry.
\vskip 0.5em
Of the 3D SDFs derived by \citet{quilez_distance_nodate} and \citet{the_art_of_code_ray_2019}, the sphere, box, and capsule were fairly trivial to translate directly to four dimensional space.
A \textbf{4D hyper sphere} takes a radius, with the surface spanning equally along all four axes.
A \textbf{4D box} takes a 4D vector where each component describes the height, width, depth and length of the box along each of the four axes respectively.
Similar to how the sphere subtracts the radius from the distance to the origin point, the box subtracts the 4D vector containing the dimensions of the box. 
To flatten the faces of the box, without the distance function stepping passed the surface, the vector is combined with the zero vector using a boolean intersection, with the use of \texttt{max(a, b)}. The derivation is best described by \citet{the_art_of_code_ray_2019}.
%TODO: interior distance
Finally a \textbf{4D capsule} can be described as a line connecting two points, \(A\) and \(B\). The line is given a thickness via subtracting a radius. Just as with the sphere, the radius spans in all four dimensions.
\vskip 0.5em
The torus is an interesting shape; two variations were developed for this project.
A \textbf{4D torus with two radii}, like a 3D torus, can be described by a major radius, $r_1$ and a minor radius $r_2$. $r_1$ is the main ring of the torus, and $r_2$ is the thickness of this ring - its radius.
When you take a 2D slice of a 3D torus it may appear as a pair of circles a distance $2(R_1 - R_2)$ apart as shown in \cref{fig:exti}. 
Similar to the cross section of a sphere, it makes sense to have the radius $r_2$ span across the fourth dimension. The 3D cross section of a four dimensional torus therefore may appear as a pair of 3D spheres.
Alternatively, consider a \textbf{4D torus with three radii}: $r_1$, $r_2$ and $r_3$. Similar to how the 3D torus can be described as a circle with a thickness, a 4D torus with three radii describes a circle defined by radius $r_1$, with radius $r_2$ surrounding the circle that is given a thickness defined by the radius $r_3$. 
Essentially this produces a circle with a torus sweeping across its path. Therefore, a 3D cross section of this torus may appear as two tori with a major radius of $r_2$ and minor radius of $r_3$ separated by a distance of $2(r_1 - (r_2 + r_3))$.
\vskip 0.5em
The 3D cross section of a \textbf{4D cone} in some instances appears as a 3D cone, and in other instances appear as a 3D sphere, in the same way a 3D cones' 2D cross section may in some cases appear as a triangle or a circle (\cref{fig:exmv}). 
The cone SDFs developed by \citet{quilez_distance_nodate} and others define the cone by its height and slope. This approach did not extend well to 4D, and defining an instance of a cone was rather unintuitive.
The developed SDF for a cone takes a height and the radius at the base of the cone. This approach extends well to $\mathbb{R}^4$, as rather than a defining the cone as a surface function of angle and height, it defines the slice of the cone at any given cross section.
\vskip 0.5em
Of the shapes defined thus far, the 4D box is the only shape with edges, meaning it would obviously stand out against the other curved surfaces. 
A \textbf{4D tetrahedron} (\textbf{pentachoron}) was created to present another platonic solid, showcasing their similarities.
The SDF of plane can be defined by its normal vector. For example, The SDF of a plane that spans $xy$ in $\mathbb{R}^3$ would be \texttt{p.z}.
A tetrahedron is made up of 4 triangular faces, each opposing one of it's four vertices. The SDF for a tetrahedron uses these vertices as the vectors describing the normal of each face. Each of these vectors defines the SDF of a plane parallel to a face of the tetrahedron. By taking the boolean intersection of these planes using \texttt{max(a, b)}, the SDF for a tetrahedron is produced.
The SDF for a tetrahedron also takes a parameter $s$, used to scale the tetrahedron. Subtracting $s$ from the distance to the surface, effectively brings the surface further from the center, similar to the radius of a sphere.
Constructing a pentachoron is done in a near identical way, just five vertices are considered rather than four.

% TODO: Figures of derivation

\begin{figure}[H]
  \begin{subfigure}[b]{0.47\textwidth}
    \includegraphics[width=\textwidth]{images/representations/timeline-sphere.png}
    \caption{Sphere}
    \label{fig:rep_timeline-sphere}
  \end{subfigure}
  %
  \begin{subfigure}[b]{0.47\textwidth}
    \includegraphics[width=\textwidth]{images/representations/timeline-cone.png}
    \caption{Cone extended along $w$}
    \label{fig:rep_timeline-cone}
  \end{subfigure}
  \\
  \begin{subfigure}[b]{0.47\textwidth}
    \includegraphics[width=\textwidth]{images/representations/timeline-capsule.png}
    \caption{Capsule extended along $w$}
    \label{fig:rep_timeline-capsule}
  \end{subfigure}
  %
  \begin{subfigure}[b]{0.47\textwidth}
    \includegraphics[width=\textwidth]{images/representations/timeline-cube.png}
    \caption{Rotated Cube}
    \label{fig:rep_timeline-cube}
  \end{subfigure}
  %
  \caption{
    The \emph{w-axis timeline} extension to the 3D cross section of a 4D object.
    \subref{fig:rep_timeline-sphere} shows a sphere. Note it scales down as the cross section moves away from the center of the object.
    \subref{fig:rep_timeline-capsule} shows a capsule - a cylinder with rounded ends - extended along $w$. There is no scaling between the cross sections.
    \subref{fig:rep_timeline-cone} shows a cone extended along $w$. As the cross section travels from the base to the tip, it decreases in size
    }
  \label{fig:rep_timeline}
\end{figure}
%
\begin{figure}[H]
  \begin{subfigure}[b]{0.24\textwidth}
    \includegraphics[width=\textwidth]{images/representations/onion-torus.png}
    \caption{Torus}
    \label{fig:rep_onion-torus1}
  \end{subfigure}
  %
  \begin{subfigure}[b]{0.24\textwidth}
    \includegraphics[width=\textwidth]{images/representations/onion-torus-2.png}
    \caption{Torus}
    \label{fig:rep_onion-torus2}
  \end{subfigure}
  %
  \begin{subfigure}[b]{0.24\textwidth}
    \includegraphics[width=\textwidth]{images/representations/onion-cone.png}
    \caption{Cone}
    \label{fig:rep_onion-cone}
  \end{subfigure}
  %
  \begin{subfigure}[b]{0.24\textwidth}
    \includegraphics[width=\textwidth]{images/representations/onion-cube-2.png}
    \caption{Cube}
    \label{fig:rep_onion-cube}
  \end{subfigure}
  %
  \caption{
    Early development of the \emph{onion skin} extension to the 3D cross section.
    \subref{fig:rep_onion-torus1} shows a torus rotated along $wx$ and $wy$ with no shift along the $w$ axis.
    \subref{fig:rep_onion-torus2} shows a torus rotated along $wy$ with a small shift along the $w$ axis.
    \subref{fig:rep_onion-cone} shows a torus rotated along $wx$ and $wy$ with a small shift along the $w$ axis.
    \subref{fig:rep_onion-cube} shows a cube rotated along $wx$ and $wy$ with a moderate shift along the $w$ axis.
    }
  \label{fig:rep_onion}
\end{figure}
%
\begin{figure}[H]
  \begin{subfigure}[b]{0.33\textwidth}
    \includegraphics[width=\textwidth]{images/representations/multi-sphere.png}
    \caption{Sphere}
    \label{fig:rep_multi-sphere}
  \end{subfigure}
  %
  \begin{subfigure}[b]{0.33\textwidth}
    \includegraphics[width=\textwidth]{images/representations/multi-penta.png}
    \caption{Pentachoron}
    \label{fig:rep_multi-pentachoron}
  \end{subfigure}
  %
  \begin{subfigure}[b]{0.33\textwidth}
    \includegraphics[width=\textwidth]{images/representations/multi-capsule.png}
    \caption{Capsule}
    \label{fig:rep_multi-capsule}
  \end{subfigure}
  %
  \caption{
    The \emph{multi-rotational view} extension to the 3D cross section of a 4D object. In each sub figure, the top left shows a regular 3D cross section of a 4D object: $S$. The bottom left shows $S$ viewed from $90^{\circ}$ on the $xw$ plane. The top right shows $S$ viewed from $90^{\circ}$ on the $yw$ plane. The bottom right shows $S$ viewed from $90^{\circ}$ on the $zw$ plane.
    }
  \label{fig:rep_multi}
\end{figure}
%
\begin{figure}[H]
  \begin{subfigure}[b]{0.33\textwidth}
    \includegraphics[width=\textwidth]{images/representations/3-4-torus.png}
    \caption{Torus}
    \label{fig:rep_4-3-torus}
  \end{subfigure}
  %
  \begin{subfigure}[b]{0.33\textwidth}
    \includegraphics[width=\textwidth]{images/representations/3-4-capsuleX.png}
    \caption{Capsule}
    \label{fig:rep_4-3-capsule}
  \end{subfigure}
  %
  \begin{subfigure}[b]{0.33\textwidth}
    \includegraphics[width=\textwidth]{images/representations/3-4-cone.png}
    \caption{Cone}
    \label{fig:rep_4-3-cone}
  \end{subfigure}
  %
  \caption{
    The \emph{4D to 3D abstraction} extension to the 3D cross section of a 4D object.
    \subref{fig:rep_4-3-torus} shows a torus rotated approximately $45^{\circ}$ about the $xw$ plane, and then $70^{\circ}$ about the $xw$ plane.
    \subref{fig:rep_4-3-capsule} shows a capsule initially extended along $w$, and then rotated $90^{\circ}$ about the $xw$ plane.
    }
  \label{fig:rep_4-3}
\end{figure}

\section{Extending 3 Dimensional Cross Sections: Representing 4D Objects}

%Union
The signed distance function referenced in the ray marching algorithm defines the scene to be rendered. In this function, several other SDFs can be referenced to render several objects within the same scene. To render several SDFs at once, each function may be combined using a boolean union: taking the minimum distance between two or more objects using \texttt{min(a, b)}.
\vskip 0.5em
%Texturing
Each extension to the 3D cross section took advantage of colouring different shapes within a scene. To colour different shapes within a scene a second function is employed that for the most part is identical to the SDF describing the scene, however it returns a number. Each value the number may take is a material index. To find what material index relates to each object in the scene, a comparison is made between the distance returned by the union of all SDFs in the scene, and the distance to a specific SDF in the scene. If they are equal, then the material index associated with that specific SDF is returned \citep{the_art_of_code_setting_2021}.

\subsection{\textit{W-axis Timeline}}
%Timeline
The simplest extension to a 3D cross section of 4D space is to render several cross sections at once, each offset by a multiple of the distance $\delta_1$ along the \(w\) axis, with each cross section being separated by a distance of $\delta_2$ along the \(x\) axis. 
The core of this concept has been explored by \citet{kageyama_visualization_2015}. In order to avoid the aforementioned problems with scaling, each cross section was built to exist side by side one another as shown in \cref{fig:exti}. 
Throughout the project, this representation has been referred to as the \textit{w-axis timeline}. Given an object under translation, passing through the hyper-plane, over time, by definition labels each cross section as a glimpse into the past or future, with respect to the primary central cross section.
A drawback of showcasing cross sections side by side is that fewer cross sections can be shown on screen at one time, in comparison to the elliptical design presented by \citet{kageyama_visualization_2015}. This problem is generally less significant for primitive shapes, such as the ones implemented for this project. The problem becomes more significant when visualising complex shapes with unpredictably changing surfaces.
Given this representation provides more information about the geometry of an object over $\mathbb{R}^4$ it is reasonable to expect that it would most effective in shape identification. The \textit{w-axis timeline} may also provide some benefit a user to predictably manipulating a four dimensional object, or identify a rotation more accurately, although this is likely to be not particularly significant, if it all.

\subsection{\textit{Onion Skin}}
%OnionSkin
Taking inspiration from 2D animation, for its time in development, the following extension was referred to as the \textit{onion skin} representation. In 2D animation, the animator may enable the onion skin tool to see a set number of frames before and after the current frame so that they may see how the animation will progress as they move forward in time. 
This representation aims for a similar approach, where the user may see backwards and forward along the \(w\) axis, rather than time. This approach follows a similar vein of thinking to the \textit{w-axis Timeline}. 
The differing factor between the two is that the \textit{onion skin} representation overlays two translucent cross sections, forward and backward along \(w\), around the main cross section as shown in 
\cref{fig:rep_onion}. The goal was to emphasise the geometry of a single object in a more cohesive manor.
The transparency of the cross sections were achieved by ray marching over 2 different distance functions. The first SDF contains all three cross sections. The second SDF just contains the central object. Two renders of the scene will be produced. By halving the colour values of both renders and overlaying them above each other, the full colour range is regained and anything that was hidden by one of the translucent objects will now be visible.

The \textit{onion skin} representation was not carried forwards to the experiment phase. Each representation was placed under trial during informal discussions with peers. The participants of this discussion generally had limited experience of the fourth dimension. The purpose of this discussion was to evaluate if a representation had potential before carrying it through to the final experiments. 
During discussions of objects under rotation whilst this representation was active showed it to be confusing and hard to follow. 
Originally the translucent cross sections were set to be a consistent distance along \(w\) from the main object, as with the \textit{w-axis Timeline}. It was found that it was not obvious that the central cross section would become either of the other cross sections as it moved along \(w\), as expected. 
In an attempt to rectify this problem, the translucent cross sections were set exist at fixed intervals along the \(w\) axis. Using this, the central cross section could be observed directly to become the translucent cross section when translated in its direction along \(w\). When the central cross section reached a translucent cross sections position along \(w\), the translucent cross sections would be shifted by a fixed amount such that the central cross section would again be directly in between the two translucent cross sections.
Despite these efforts, this representation was still deemed to confusing for users as was subsequently set aside for the rest of development.

\subsection{\textit{Multi-rotational View}}
%Multi-view
\textit{Polyvision}, proposed by \citet{matsumoto_polyvision_2019} extends a 3D shadow wireframe of a 4D object by introducing the ability to view the object from multiple angles. Viewing an object from multiple angles at once provides a great deal of insight into the geometry, and also in identifying the rotations it may undergo.
A similar representation of 4D geometry was applied during this project over 3D cross sections of 4D objects. Throughout the duration investigation this representation has been referred as the \textit{multi-rotational view} or \textit{multi-view} for short.
In order to view the same cross section from three other angles, the SDFs for four objects are rendered in total, with the three of the objects oriented $90^{\circ}$ about the $xw$, $yw$, $zw$ planes respectively. 
In order to differentiate they four cross sections they were coloured differently. Conventionally, the \(x\), \(y\) and \(z\) axes are coloured red, green and blue respectively. Therefore the cross section that was rotated about the $xw$ plane was coloured red, the cross section that was rotated about the $yw$ plane was coloured green and the cross section that was rotated about the $zw$ plane was coloured blue; as shown in \cref{fig:rep_multi}.
One of the biggest strengths of the \textit{multi-view} representation its ability to clearly convey the behaviour of a slice of 4D geometry under rotation; although it can be challenging to comprehend at first.
Another positive of the \textit{multi-view} representation is its ability to effectively provide enough information to determine the shape that is being viewed, without requiring a user to first interaction with the object to verify their hypothesis.

\subsection{\textit{4D to 3D Abstraction}}
%4D to 3D
The most risky extension to the 3D cross section of a given 4D object, within this investigation, attempts to abstract 4D rotations (any plane of rotation involving the \(w\) axis) to 3D rotation. The goal of this representation is to assist users in better understanding an object undergoing rotation over time, as well as improving the accuracy of the manipulation of 4D geometry.
The representation, referred to in this project as the \textit{4D to 3D abstraction}, takes a 3D object to complement the main 4D object. The 3D object will mimic a 4D planar rotation ($xw$, $yw$ or $zw$) with the 3D axial rotation ($x$, $y$ or $z$ axes; equivalent to the $yz$, $xz$ and $xy$ planes of rotation respectively) utilising the 3D axis involved with the four dimensional rotation. For example: if the main 4D object is rotating about the $yw$ plane, the 3D counterpart will rotate about the $y$ axis (or the $xz$ plane).
In order to render a window with a separate 3D object on screen, a second plane was spawned into the scene in Unity to render the ray marched 3D object. A second camera facing the plane allowed for a window displaying the 3D object to be rendered to a UI panel.
The 3D object can be configured such that it is the 3D shape analogous to the main 4D shape on screen, or the 3D shape may be independent from the main 4D shape. During the experiment, the 3D shape is configured to be a 3D cube. 
The advantage of using a cube comes with its consistent right angles. The 3D cube conveys reasonably well how far away from a right angle the 4D object is, with respect to the global axes, as shown in \cref{fig:rep_4-3}.

The primary advantage of this representation is also a risk. The \textit{4D to 3D abstraction}, as mentioned earlier, abstracts the 4D rotation to a 3D rotation. As a result, it becomes very quick to identify what rotations are occurring with the main 4D object. This can be helpful for beginners, but unless considered with a critical eye, runs the risk of not teaching users how four dimensions works, and instead provides an answer to a question without a user considering why the 3D cross section of an object behaves in the way that it does.
Whilst this may not invalidate the extension, it is worth noting that the \textit{4D to 3D abstraction} representation is not extendable across \(n\) dimensions. Every other representation thus far could in theory be used in any dimension greater than two. This abstraction however relies on their being three more rotations in four dimensions, that can be directly mapped to the three planes of rotation in 3D. Considering five dimensional space: there are ten planes of rotation. If you tried to map 5D rotations to 4D; only three of the four new planes of rotation could be considered.
This representation is expected to provide an increase of accuracy in the manipulation of 4D objects, as well as correctly interpreting any rotations it may undergo over time. This representation does not however provide any more information about the geometry of the object being handled, unlike the aforementioned representations.

\section{Rotation of a 4D Vector}

As discussed in \cref{ga_and_rotor}, geometric algebra provides a platform for stable rotation of a vector in $\mathbb{R}^4$ without gimbal lock. 
The rotor is straightforward to work with when considering the abstract multivectors as single entities. Implementing a rotor in code, on the other hand, is a more complex task. 
A rotor is made up of three multivectors: A scalar, a bivector and a pseudo-scalar. To perform arithmetic operations on non-scalar multivectors, they must be broken down into projections. 
\vskip 0.5em
In $\mathbb{R}^4$ a grade 1 multivector (Vector) \(a\) can be broken down into four components. Each component is the vector projected onto one of the four axes (\cref{eq:vec_components}). One of the four projections is therefore a scalar value describing the vectors distance along an axis (\cref{fig:vec_proj}).
%
\begin{equation}
  \label{eq:vec_components}
  a = a^x + a^y + a^z + a^w
\end{equation}
%
In $\mathbb{R}^4$ a grade 2 multivector (Bivector) \(b\) is described by its area and orientation in space. A bivector can be broken down into six components, where each component is the bivectors projection onto each plane that can be taken from the four axes (\cref{eq:bivec_components}). A projection of the bivector onto a plane is a scalar value equivalent to the area of the projected bivector which will be less than or equal to the area of the bivector (\cref{fig:bivec_proj}).
%
\begin{equation}
  \label{eq:bivec_components}
  b = b^{xy} + b^{xz} + b^{xw} + b^{yz} + b^{yw} + b^{zw}
\end{equation}
%
As stated above, a rotor in $\mathbb{R}^4$ is comprised of a grade 0 multivector (Scalar) \(s\), a bivector and a grade 4 multivector (pseudo-scalar) \(p\) (\cref{eq:rotor_components}). The bivector defines the plane of rotation to rotate the vector about. The scalar describes how much to rotate the vector by. The pseudo-scalar is required for 4D rotation to normalise the rotor and ensure stable rotation; without it the vector may rotate unpredictably or increase/decrease in size.
%
\begin{equation}
  \label{eq:rotor_components}
  R = s + b + p^{xyzw} = 
  s + b^{xy} + b^{xz} + b^{xw} + b^{yz} + b^{yw} + b^{zw} + p^{xyzw}
\end{equation}
%
\begin{equation}
  \label{eq:rotor_rev}
  R^{\dagger} = s - b - p^{xyzw} = 
  s + b^{xy} - b^{xz} - b^{xw} - b^{yz} - b^{yw} - b^{zw} - p^{xyzw}
\end{equation}
%
\citet{bosch_4d_2011} provides a code template written in C++ for a \texttt{Rotor4} in his initial blog post describing the rotor. Following his interactive article - an Introduction to Rotors - describing properties of geometric algebra in detail \citep{bosch_lets_nodate} Bosch provides a completed \texttt{Rotor3} class, compared against a Quaternion implementation \citep{bosch_code_nodate}. With this wealth of information, the foundations for the rotor could be implemented in Unity, C\#. The 4D rotor however was incomplete. 
Whilst Bosch provided a completed \texttt{Rotor3} class, the $\mathbb{R}^4$ rotor-rotor product, and the $\mathbb{R}^4$ rotor-vector-sandwich product (the rotation of a vector) where not. 
\vskip 0.5em

\begin{figure}
  \begin{subfigure}[b]{0.45\textwidth}
    \includegraphics[width=\textwidth]{images/rotation/projection_vec.png}
    \caption{The components of a vector}
    \label{fig:vec_proj}
  \end{subfigure}
  \begin{subfigure}[b]{0.45\textwidth}
    \includegraphics[width=\textwidth]{images/rotation/projection_biv.png}
    \caption{The components of a bivector}
    \label{fig:bivec_proj}
  \end{subfigure}
  \caption{The projection of multivectors in $\mathbb{R}^3$ onto their basis blades. 
  \subref{fig:vec_proj} shows the projections of a vector, parallel to the appropriate axes, stemming from the tip of the vector.
  \subref{fig:bivec_proj} shows the projections of a bivector, constructed of two vectors, onto its basis planes.}
  \label{fig:projections}
\end{figure}

A multivector is considered as a sum of its projections, as shown above. In order to multiply two multivectors using the geometric product, the multivectors can be multiplied out given its distributive properties. As such, referencing a 4D geometric product multiplication table \citep{baker_maths_nodate-1}, the subsequent multivector can be derived.
\cref{eq:geo_prod} shows how two multivectors can be multiplied using the geometric product with two vectors \(a\) and \(b\) in  $\mathbb{R}^3$ using the appropriate geometric product multiplication table \citep{baker_maths_nodate}.
%
\begin{equation}
  \label{eq:geo_prod}
  \begin{split}
    a = a^x + a^y + a^z\\
    b = b^x + b^y + b^z\\
    a*b = &+(a^x * b^x + a^x * b^y + a^x + b^z)e^x\\
          &+(a^y * b^x + a^y * b^y + a^y + b^z)e^y\\
          &+(a^z * b^x + a^z * b^y + a^z + b^z)e^z\\
    a*b = &+(e + e^{xy} - e^{zx})e^x\\
          &+(-e^{xy} + e + e^{yz})e^y\\
          &+(e^{zx} - e^{yz} + e)e^z\\
  \end{split}
\end{equation}
%
Initially the equations for the rotor-rotor product and the rotation of a vector where derived by hand, using the same process as \cref{eq:geo_prod}. 
When testing the rotation of 4D objects however, there were consistent errors in their behaviour. Examples of these issues include: dramatic scaling, surface errors with ray marching, objects not rotating along the expected planes of rotation. These issues were focused around the vector produced from the rotor-vector sandwich product (\cref{eq:sandwich_a}). 
\vskip 0.5em
Deriving the sandwich product by hand proved challenging, given that order matters as per the anti-commutative properties of multivectors. The process also produces grade 3 trivectors, which have influence over the rotated vector. 
\texttt{GAlgebra} is a package for symbolic geometric algebra calculus in python. The package was used to derive the appropriate equations for the rotor. This method of derivation proved far more reliable, although translating the equations to C\# proved very tedious. The code to produce the equations can be found in \cref{lst:rotor_derivation}.
The final equations are grouped into their multivector components. The final equation to rotate a vector (\cref{eq:vec_components}) using a rotor (\cref{eq:rotor_components}) and its reverse (\cref{eq:rotor_rev}) is grouped into the four components that make up the rotated vector. The equation to rotate a vector: \cref{eq:rotate_vec}. The geometric product of two rotors \(a\) and \(b\) produces the equation (\cref{eq:rotate_rotor}) and is grouped by a rotors eight components.

\section{Methods of Rotation}
\label{interaction}

The first challenge in rotating ray marched 4D shapes was passing the information to the shader. Unity's shader lab allows the programmer to implement and adjust properties of the shader. This is normally used for changing the colour or roughness. The shader properties used to manipulate ray marched objects included the $(x,y,z,w)$ translation of the origin point, as well as the eight components of the Rotor used to rotate the object. \cref{eq:rotate_vec} was implemented in the shader to rotate any vector in the scene according to the eight rotor component shader properties.
\vskip 0.5em
Two methods of rotation were developed; only swipe based input was implemented. 
Swipe based input takes mouse delta values and keyboard inputs to rotate an object in the direction of mouse movement, allowing a user to restrict the plane of rotation through a keyboard input.
Grab ball rotation was an attempt to expand upon the most commonly employed method of 3D rotation. Three arcs, or in the case of 4D: six hyper tori, each controlling a different plane of local rotation for the object.
\vskip 0.5em
Arcball or the virtual sphere can be used in 4D, as discussed in \cref{background_rotation}. 
Swipe based rotation is simple to implement, and allows for restricting the planes of rotation. Therefore it was the minimal viable product in the development of an intuitive rotation mechanic.
Whilst it would have been desirable to explore manipulation tools such as arcball or the virtual sphere, the allocated time versus the time of development did not allow for detailed exploration or development of such mechanics.

\subsection{Swipe Based Input - Rotation About The Global Axes}

Swipe based rotation mechanics are simple to implement and straightforward to understand. Restricting the plane of rotation allows users to be deliberate in the actions they take. A disadvantage of swipe based rotation in comparison with arcball or the virtual sphere, is requiring a secondary input to switch between dimensions.
\vskip 0.5em
Beginning with 3D swipe based rotation. Left clicking the mouse button and dragging it across the screen yields a delta value; a \texttt{Vector2} describing the difference in the $x$ and $y$ mouse positions between the current and previous frame.
Using this information, the plane of rotation may be specified: an upward swipe ($y$) will rotate about the $yz$ plane, and a sideways swipe ($x$) will rotate about the $xz$ plane. 
Taking the mouse delta values and multiplying them by a \texttt{speed} constant allows them to be used as the input angle of rotation.
The implementation allows a user to hold the \texttt{x} and \texttt{y} keys to restrict the plane of rotation about the $x$ and $y$ axes ($yz$ and $xz$ planes) respectively. 
To rotate about the $z$ axis ($xy$ plane), the user may hold the \texttt{z} key.
To calculate the angle of rotation, the screen is divided into vertical and horizontal halves to produce a basic equation for translating circular motion to linear values. The user may then rotate the mouse in a circle about the center of the screen to produce the matching rotation.
\vskip 0.5em
The 3D rotation controls may extended to four dimensions, keeping 3D rotation to the same as before; using the left mouse button. The right mouse button is then in control of 4D rotation. The mouse delta values are again used to control rotation in the $xw$ and $yw$ planes, respective to the $x$ and $y$ delta values.
A user may restrict the planes of rotation using the same keys as before. Holding the \texttt{x} key will restrict the rotation to the $xw$ plane, and holding the \texttt{y} will restrict the rotation to the $yw$ plane. Holding the \texttt{z} key allows the user to rotate about the $zw$ plane, where a user may move the cursor, again in a circular motion, to rotate the object.
\vskip 0.5em
Although the resulting rotation mechanic does not give the user control relative to the objects local axes, it received a warm reception during informal discussions with participants. It appears intuitive and easy to grasp. 
Separating the left and right click of the mouse to three and four dimensional rotations respectively, in combination with the ability to restrict the planes of rotation, allows users to be deliberate and purposeful with their actions.

\subsection{4D Grab Ball - Rotation About The Local Axes}

The most commonly employed method of controlling the rotation of an object, is with the use of a grab ball (as it is referred to in this paper). The grab ball provides a user with control over an objects rotation, relative to the objects local axis. The grab ball is well suited to a 2D interface, allowing a user to rotate an object without the need for a secondary input to switch dimensions.
\vskip 0.5em
In $\mathbb{R}^3$ dragging the mouse across each of the three arcs controls each of the three planes of rotation independently.
Different software approaches the method of interaction in different ways. 
Unity's rotation tool appears to rotate geometry as the cursor follows the path tangent to the arc, from the point at which the user clicked on the arc. This tangent line is not indicated to a developer, and therefore rotation can sometimes feels rather clunky.
\vskip 0.5em
Initial exploration of the grab ball, began with an implementation in $\mathbb{R}^3$. As with Unity's implementation, the system was designed such that a rotation occurs as the cursor is dragged along the tangent relative to the point of contact with an arc. To improve upon Unity's implementation, a tangent line is rendered to the screen in order to guide the users actions, as shown in \cref{fig:grab1}. 
To rotate the grab ball itself, Unity's \texttt{transform} was used,rotating the ball with the use of quaternions.
After some improvements, the interaction in $\mathbb{R}^3$ seemed intuitive and promising.
\vskip 0.5em
To rotate an object in four dimensions, a toggle was initially implemented, such that the three arcs would switch from the 3D planes of rotation, to the 4D planes of rotation (involving \(w\)).
As the grab ball was rotated using a quaternion, it was held stationary when manipulating the geometry in 4D planes of rotation.
This resulted in the first failure. Rotating in multiple planes of 4D rotation should effect the grab ball, and as a result the object and grab ball would no longer be in sync. This is shown in \cref{fig:grab2}. Furthermore, a four dimensional grab ball would require six arcs, one for each plane of rotation.
\vskip 0.5em
Exploring the idea of the grab ball further, an SDF of a grab ball was developed: The union of six tori, each with their major radius spanning each of the six planes of rotation.
To select an object, a ray cast is emitted from the cursor position on screen. A collider is required for the ray cast to detect the object it has interacted with. The ray marched shader has no collider and therefore cannot be interacted with, unlike the mesh based arcs.
The ray marched grab ball however, does provide some insight. 
The 4D tori are still being viewed as a 3D cross section. As shown in \cref{fig:grabballs-arcs}, rotating the grab ball in four dimensions morphs the arcs. As the arc may just appear as two spheres, it can become impossible to predict the plane of rotation the object may rotate in, when grabbing a particular arc. 
Furthermore, as shown in \cref{fig:grab3}, as the arcs are the same size, and only a slice of them may be seen at a given time, three of the six arcs are invisible - obscured by the other three.
\vskip 0.5em
Given more time for this investigation, research would be conducted into controlling the mesh of an arc through the use of a rotor, to rotate it in $\mathbb{R}^4$. It would be interesting to explore the shadow of a four dimensional grab ball, and how it may behave.
Equally, it may be possible to define a collider synced to the ray marched grab ball. Explore how to control such an entity despite only a portion of it being visible at a given time, may prove more intuitive than one might expect.

\begin{figure}
  \hspace{1.6cm}
  \begin{subfigure}[b]{0.35\textwidth}
    \includegraphics[width=\textwidth]{images/rotation/grabball-3D.PNG}
    \caption{
      Rotations in 3D
    }
    \label{fig:grab1}
  \end{subfigure}
  \hspace{0.8cm}
  \begin{subfigure}[b]{0.35\textwidth}
    \includegraphics[width=\textwidth]{images/rotation/grabball-3D-offset.PNG}
    \caption{
      After rotations in 4D
    }
    \label{fig:grab2}
  \end{subfigure}
  \label{fig:grabballs-arcs}
  \caption{
    Interactive mesh based arcs. When interacted with, an arc will overlay a tangent line which the path should follow. This works well for 3D rotation \subref{fig:grab1}. When rotating in 4D, the grab ball remains stationary. As such, it becomes offset from the geometry \subref{fig:grab2}.
  }
\end{figure}

\begin{figure}
  \begin{subfigure}[b]{0.33\textwidth}
    \includegraphics[width=\textwidth]{images/rotation/grabball-torii.PNG}
    \caption{
      Not rotated in 4D
    }
    \label{fig:grab3}
  \end{subfigure}
  \begin{subfigure}[b]{0.33\textwidth}
    \includegraphics[width=\textwidth]{images/rotation/grabball-torii-split-2.PNG}
    \caption{
      Small rotation in 4D
    }
    \label{fig:grab4}
  \end{subfigure}
  \begin{subfigure}[b]{0.33\textwidth}
    \includegraphics[width=\textwidth]{images/rotation/grabball-torii-split.PNG}
    \caption{
      Large rotation in 4D
    }
    \label{fig:grab5}
  \end{subfigure}
  \label{fig:grabballs-tori}
  \caption{
    Ray marched grab ball concept using six tori. 4D arcs are lighter in colour to the 3D arcs. \subref{fig:grab3} shows the 4D arcs are hidden, and would be inaccessible. If rotated in 4D, the arcs begin to change, overtime indicating less and less what the result of interaction may be (\subref{fig:grab4}, \subref{fig:grab5}).
  }
\end{figure}

%====

\begin{figure}[H]
  \begin{subfigure}[b]{0.25\textwidth}
    \includegraphics[width=\textwidth]{images/textures/no-pattern-rgbw.png}
    \caption{
      RGBW
    }
    \label{fig:tex1}
  \end{subfigure}
  \hspace{1cm}
  \begin{subfigure}[b]{0.30\textwidth}
    \includegraphics[width=0.83\textwidth]{images/textures/pattern-direction.png}
    \caption{
      Directionally Coloured Pattern
    }
    \label{fig:tex2}
  \end{subfigure}
  \hspace{0.5cm}
  \begin{subfigure}[b]{0.25\textwidth}
    \includegraphics[width=\textwidth]{images/textures/pattern-rgbw.png}
    \caption{
      RGBW Coloured Pattern
    }
    \label{fig:tex3}
  \end{subfigure}
  \caption{
    Quad-planar projection of colours and textures using the components of 4D normal vectors.
    \subref{fig:tex1}, positive components are coloured $x$: Red, $y$: Green, $z$: Blue and $w$: white. Negative are dark and shaded with diffuse lighting.
    \subref{fig:tex2}, patterns projected along each axis. negative components are coloured Blue, and positive are coloured Red.
    \subref{fig:tex3}, patterns projected along each axis. Positive components coloured $x$: Red, $y$: Green, $z$: Blue and $w$: white. Negative are dark and shaded with diffuse lighting.
  }
  \label{fig:textures}
\end{figure}

\section{Texturing Ray Marched Objects}

Two cubes, offset by a multiple of $90^{\circ}$ from each other will look identical. It is important to be able to distinguish the pose of two given symmetric objects of the same shape. Texturing the faces with colours and patterns allows a user to distinguish two otherwise identical shapes.
Texturing the three dimensional cross section of four dimensional objects is a rather odd task given only a slice of the object can be seen at a given time.
In ray marching, the common method of texturing objects is through normal based projection - also known as tri-planar projection \citep{the_art_of_code_how_2020}. 
Given an un-rotated object in $\mathbb{R}^3$, colours and textures can be projected onto the object according to the surface normal. The components of the normal vector can be mapped to the intensity of the projections. For example, multiplying the vector $(1,0,0)$ with a colour/texture would only project the texture along the $x$ axis.
Extending tri-planar projection to $\mathbb{R}^4$ utilises the 4D normal vector. Given the six planes of rotation, when a pattern is projected onto the cross section, it may morph under rotation. This makes some sense given a pattern is being projected from a direction we cannot see.
\vskip 0.5em
A common method of representing the surface normal in 3D is to map the three components of the normal vectors to the three primary colours: Red, Green and Blue. The origin point of the local axes exist in the center of the object. Therefore, components of the normal vector may be positive or negative. To distinguish all six sides of a shape in $\mathbb{R}^3$, if the vector component is positive, it may be coloured (RGB), otherwise it will be black. By adding the lighting to the surface of the object, the black sides of the object can be distinguished.
\vskip 0.5em
Three methods of distinguishing the shapes were explored in this project: \textit{RGBW}, \textit{Directionally coloured patterns} and \textit{RGBW coloured patterns}; alongside the un-coloured diffuse lighting. 
\textit{RGBW} (\cref{fig:tex1}) builds upon the RGB colouration method of distinguishing faces. Given there are four components of the normal vector in $\mathbb{R}^4$, but only 3 primary colours, a surface facing the $w$ axis will be coloured white.
To more clearly emphasise the difference between the direction of a surface of an object, a pattern can be projected along each axis. 
Four different patterns patterns where developed, and projected along each axes. To distinguish the positive and negative directions of the surface normal, the patterns must be multiplied by a colour. One colour scheme implemented was to colour the negative direction blue and the positive direction red (\cref{fig:tex2}). The other was to mix the \textit{RGBW} colour scheme with the patterns (\cref{fig:tex3}).

\section{Collecting Data}

\subsection{Data Format}

Collected data was stored in a JSON format (\cref{lst:json}) for its ease of assembly and analysis. The Unity plugin: SimpleJSON \citep{bunny83_simplejson_nodate} allows for easy reading and writing and of JSON data.
The data was separated by tasks per representation. Each task was repeated several times per representations, with each task collecting data such as: time taken, participant answers, the pose of objects on screen, and participant survey responses held after each task. Data was not analysed prior to collection as analysis tools would be developed after the fact.

\subsection{Remote Data Collection}

Given the pandemic at the time of this project, it was necessary, for the purposes of collecting as much data as possible, that this experiment could function remotely. As stated, the project was built in Unity, allowing for easy building to WebGL, meaning the experiment could be hosted online. Unity's WebGL builds, and sites hosting WebGL builds, such as \href{https://itch.io/}{\textit{itch.io}} and \href{https://www.newgrounds.com/}{\textit{newgrounds.com}}, implement security precautions making data collection a troublesome task.
During runtime, the data is stored to a persistent data path. This worked well for local testing, however downloading the file from online hosting is not possible without setting up a database.
\vskip 0.5em
\subsubsection{Collecting Data via Automatic Email}~
\vskip 0.2em
An attempt was made to sending the data file through email upon the completion of the experiment. Unfortunately, some online hosting platforms, browsers and network configurations do not allow the sending of an anonymous email through a third party server for the sake of security. 
\vskip 0.5em
\subsubsection{Collecting Data via Copy \& Paste}~
\vskip 0.2em
Unity enables a programmer to copy a string to the system clipboard. A button was implemented that would allow a user to copy the collected data to their clipboard in order to manually email the data for collection. WebGL builds, however, do not allow the use of copying to a system clipboard. The Unity plugin: WebGLInput \citep{kou-yeung_webglinput_nodate} allows for copying and pasting through the use of text boxes.
The data was collected remotely from users via a copy/paste text box that would appear at the end of an experiment.

%==================================================================================================================================
\chapter{Evaluation} 

\section{Aims} 

This investigation aims to evaluate the effectiveness of each of the three extensions to the 3D cross section of 4D geometry. Each extension has the potential to benefit a viewers understanding with respect to different aspects of geometry. Therefore the goal of the investigation is to evaluate what aspect of geometry, if at any, each of the three representations may assist a user in interpreting. To reiterate \cref{aims}: Which representation is more effective at conveying the surface geometry, the rotational pose, or assisting a users in manipulate geometry in $\mathbb{R}^4$ ?

\section{Preliminary Research}

\subsection{How to Teach Others}

To properly take advantage of, and evaluate each of the developed extension to the 3D cross section, a participant needed to understand the foundations 4D space. 
As expected, many participants had little or no experience in 4D geometry, as shown in the responses to questionnaire (\ref{questionnaire}).
The tutorial video was structured with the goal of effectively teaching inexperienced participants prior to the experiment (\cref{tutorial}). The script for the video was drafted and tested several times with peers to tune the descriptions and explanations of complex topics to be clear and concise. 
The explanation for the rotation of geometry within and outside of the dimensions of the cross section is a notable example of a portion of the script that underwent several rewrites before viewers felt it was adequate.
\vskip 0.5em
During the development of each representation, preliminary evaluations were conducted to see if each extension had potential in assisting users in their interpretation of geometry. As discussed, the \textit{onion skin} representation proved unintuitive and too complex to digest for inexperienced users. Peers favoured the \textit{w-axis timeline} as a less confusing alternative. As such, only three of the four developed representations were carried forward to experimentation.

\subsection{Repeated Preliminary Experiments}

The system was developed over the foundation that it was to be repeatedly tested and improved. 
In order to gather the best data, the experiment should not rush the user more than necessary. The experiment should also not last so long that it wears the participant down and affects their results. To collect as much good data as possible, the timing of the experiment could not require an unreasonable commitment from potential participants. As such, the experiment was repeatedly tested and balanced to provide a user with an experience that allowed them to take their time, but did not last so long that it may wear them out, or deter people from participation.
\vskip 0.5em
For the experiment to be successful it must provide clear explanations of the experimental process and components participants will be interacting with, such as the extensions to the 3D cross section. Every piece of text was proof read by peers with little experience, in order to ensure the experiment was clear and concise.

\section{Tasks and Parameters}
\label{params}

\begin{figure}
  \begin{subfigure}[b]{0.33\textwidth}
    \includegraphics[width=\textwidth]{images/tasks/shape_match.PNG}
    \caption{
      Shape match
    }
    \label{fig:task_s}
  \end{subfigure}
  \begin{subfigure}[b]{0.33\textwidth}
    \includegraphics[width=\textwidth]{images/tasks/rotation_match.PNG}
    \caption{
      Rotation match
    }
    \label{fig:task_r}
  \end{subfigure}
  \begin{subfigure}[b]{0.33\textwidth}
    \includegraphics[width=\textwidth]{images/tasks/pose_match.PNG}
    \caption{
      Pose match
    }
    \label{fig:task_p}
  \end{subfigure}
  \caption{User Interface layout for each task using the Control representation.}
  \label{fig:tasks}
\end{figure}

The experiment was separated into a series of repeated task. Each task would be repeated several times for each representation. Each task would try to capture the representations effectiveness at conveying a different aspect of geometry.

\subsection{Shape Matching}

The goal of shape matching is to evaluate a representations effectiveness at conveying the surface geometry of a 3D cross section of a 4D object.
Given a random object, in a random pose, positioned randomly along the $w$ axis, a user must identify the shapes 3D analogous counterpart. A user may select the shape they believe to be on screen using a menu on the left.
(\cref{fig:task_s}).
To encourage users to interact with the object, and not make premature assumptions, the cone and capsule were biased such that their cross sections would appear as a sphere 35\% of the time.
The participant was allotted twenty seconds to play with and identify the shape on screen.

The cross section of different objects, such as the hyper-cube and pentachoron may appear similar. When textured, however, will have distinct colours or patterns, making them more easily identifiable. As such, the objects on screen where coloured exclusively white with diffuse lighting as to avoid bias where a user may identify a relationship between the patterns and shapes. 
All of the developed shapes were included in this task, summing to six 3D objects, analogous to seven 4D objects.

After each attempt at the task, the participant was asked how confident they were in their answer. The participant was also asked if they felt they could relate what they saw in the 3D cross section of a 4D object to an analogous 3D to 2D example. These metrics would assist in differentiating blind guesses from an actual understanding.

\subsection{Rotation Matching}

The goal of rotation matching is to evaluate a representations effectiveness conveying to a user the rotations a 4D object may undergo; allowing a user to identify any active planes of continuous rotation.
A given random object may rotate in up to three planes of rotation at once. There is a 100\% chance of at least one 4D rotation (involving the \(w\) axis), approximately a 33\% chance of a second 4D rotation, and a 30\% chance of a 3D rotation.
A user may select from a menu on the left hand side all of the planes of rotation they believe may be active. (\cref{fig:task_r}).
The participant was informed prior to this task that their may be between one and three planes of rotation, with a maximum of one 3D rotation at a given time.
The participant was allotted sixty seconds to play with and identify the shape on screen.
The sphere was not included for this experiment as its cross section does not change shape under rotation. 
Furthermore, all objects where textured given it may be impossible to identify a rotation if an object has no surface imperfections.

As with the shape matching task, after each attempt the participant was quizzed on their confidence and understanding.

\subsection{Pose Matching}

The goal of pose matching is to evaluate a representations effectiveness in assisting a user when manipulating geometry.
Given a primary object in the same on-screen position as with the other tasks, and a secondary randomly oriented object in the top of the screen, a user must rotate the primary object to match the pose of the secondary object. (\cref{fig:task_p}).
The secondary object is randomly rotated exclusively along the 4D planes of rotation. 
Rotating the primary object using 3D rotation will simultaneously rotate the secondary object in 3D. The purpose of this is to allow a user to check all sides of the two shapes match, otherwise you may just be looking at a single side of the secondary object, with no hint of similarity between the two objects.
The participant was allotted three minutes to manipulate the shapes on screen to match their orientation as closely as possible.
As with rotation match, the sphere was not included. All objects utilised a pattern texture to correctly identify the similarity between the two objects.

After the completion of each attempt the user was asked to rate the difficulty of the task. The difficulty may indicate if some shapes are easier to manipulate, and if a representation appears to assists users in the manipulation of geometry.

\subsection{Task Format}

It was expected that as users learned the behaviour of 4D shapes, they would improve. To avoid this bias leaking into the data, representations were presented in a random order. A control representation was included, without any extension to the 3D cross section being utilised.

Each representation would be subject to five iterations of shape matching, five iterations of rotation matching, and three iterations of pose matching, respectively.
After each representation, the user would be shown graphs detailing their accuracy. The purpose of this was to keep participants engaged and attentive.

\section{Limitations}
\label{limiations}

The experimentation process for this investigation suffers from limitations that may limit the quality of the data collected. 
A notable drawback is the lack of time per task. Given the need to limit the time of a single experiment, time limits were placed on each task. The twenty seconds alloted to the shape match task proved too little, resulting in participants failing to answer in time (\cref{fig:shape_stats}). 
For users with limited experience, there will be a moderately steep learning curve given the length of time an experiment may run for. Data will be varied based on different participants rate of learning, and as such, there likely is not enough evidence to draw any firm conclusions.
Furthermore, the data may biased against participants who participated remotely due to poor performance when the application is run in WebGL. The w-axis timeline, and multi-rotational view both have to render a fairly intensive scene, and as such tend to lag in browser.

\section{Results}

The following data is compiled from a total of 11 participants. All participants remained anonymous and provided explicit permission for their data to be analysed. During the experiment participants were asked to answer questionnaire (\ref{questionnaire}).
When asked how a participant learns best; 5 participants identified as a kinesthetic learner, 4 as a visual learner, and the remaining 2 learn best through reading and writing.
Of the 11 participants, 3 had never heard of four dimensions before. 5 participants had briefly explored the concept through a personal interest. The remaining 3 were familiar with higher dimensionality in the form of data science and mathematics.

\subsection{Quantitative Results}

\subsection*{Shape Matching}

%correct over time
Each participant become more familiar with the geometry of 4D shapes as they spent more time with them. As shown in  \cref{fig:shape_stats}, participants answered more accurately over time; where each iteration follows the introduction of a new representation in random order.
%submission time over time
Following this, \cref{fig:shape_stats} shows that participants were quicker to answer with each iteration of a new representation.
\vskip 0.5em
%correctness per representation
What is surprising; participants were most correct when using the control representation, and performed worst with the w-axis timeline.
Whilst running the experiment in browser, the performance would decrease as the complexity of a ray marched scene increased.
Furthermore, through discussion with participants, it appears a common theme that they felt they performed worse if there is more content to digest.
These two elements are backed up by the time taken to answer per representation (\cref{fig:shape_stats}), where participants were much more likely to expire the twenty second time limit when interacting with representations rendering more content.
\vskip 0.5em

\begin{figure}
  \centering
  \includegraphics[width=0.8\textwidth]{images/results/shape_matching_stats.png}
  \caption{Shape matching correctness and timings}
  \label{fig:shape_stats}
\end{figure}

% correctness and confidence
Encouragingly, a positive correlation can be seen between a participants correct answers and their confidence and understanding of their submission (\cref{fig:shape_corr}). Their confidence was rated on a scale of 0 to 10, and their understanding was a binary answer: "yes" or "no".
This correlation suggests that participants were not making blind guesses.
% time taken
A strong correlation can also be seen between a participants confidence and how long they took to answer the question; suggesting a participant took longer to submit their answer if they were not confident in it.
Following this, a decrease in correctness and understanding correlates with an increased time to answer (\cref{fig:shape_corr}).
\vskip 0.5em
% correlations per shape
As stated in \cref{params}, the cone and capsule had the potential to appear as a sphere. This may be a potential reason as to why participants were less likely to be correct when tasked with identifying the cone (\cref{fig:shape_corr}).
On the other hand, users rarely incorrectly identified a torus. This is unsurprising as the torus is a very distinct shape.
As expected, users would interact far more with the sphere, to indeed verify it was a sphere, given it will not change under rotation. This is indicated by the increased swipe count, used to rotate objects on screen (\cref{fig:shape_corr}).
\vskip 0.5em
% correlations per rep
Users tended to be less confident when using the w-axis timeline, and more confident whilst handling the control representation. This goes hand in hand with the correctness of a participants submission.
Interestingly, participants tended to rotate objects more when using the multi-rotational view representation, despite already viewing objects from alternate perspectives. 
Participants also used the w-axis slider less for this representation.
On the other hand, participants tended to use the w-axis slider more, and rotate the object less when using the 3D abstraction of 4D rotation. Given the 4D to 3D abstraction does not show any more information about the objects surface than the control representation, it is odd users handled it differently (\cref{fig:shape_corr}).

\begin{figure}
  \centering
  \includegraphics[width=0.8\textwidth]{images/results/shape_matching_correlations.png}
  \caption{Shape matching correlations. "W Count": number of interactions with the $w$ axis slider. "Swipe Count": number of rotations applied to the object. "Initial Rotation": The distance from $90^{\circ}$ of the angle of the initial pose relative to no rotation}
  \label{fig:shape_corr}
\end{figure}

\subsection*{Rotation Matching}

The active planes of continuous rotation were recorded as a $1 \times 6$ boolean array. Two boolean arrays were collected: The loaded active planes of rotation, and the planes of rotation a participants suspected to be active. The similarity of two boolean arrays, $A$ and $B$, can be calculated using the jaccard index \cref{jaccard}, \citep{glen_jaccard_2022}.
%
\begin{equation}
  \label{jaccard}
  J(A, B) = \frac{|A \cap B|}{|A \cup B|}
\end{equation}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.8\textwidth]{images/results/rotation_matching_stats.png}
  \caption{Rotation matching correctness and timings}
  \label{fig:rot_stats}
\end{figure}

% per iteration
With each iteration of a new representation, there appears to be a slight increase in accuracy, indicated by the quantity of perfect answers, and the similarity using the jaccard index (\cref{fig:rot_stats}).
Furthermore, the time taken to answer clearly decreases as users spent more time with 4D shapes.
\vskip 0.5em
% Representations
Participant performance when using the 4D to 3D rotational abstraction proved better than any other representation for all three metrics: totally correct answers, similarity of an answer, and the time taken to answer (\cref{fig:rot_stats}). 
Furthermore, participants were more confident in their answers whilst using this representation. Whilst this representation proved most effective in assisting users to identify the active planes of rotation, there is a debate as to whether this representation just gave the answer away, or if participants critically considered what they were seeing on screen.

\begin{figure}[H]
  \centering
  \includegraphics[width=0.8\textwidth]{images/results/rotation_matching_correlations.png}
  \caption{Rotation matching correlations. "Number of Rotations": The number of active planes of continuous rotation.}
  \label{fig:rot_corr}
\end{figure}

On the other hand, the multi-rotational view representation has a notably lower quantity of totally correct answers compared to the other representations. This trend can also be seen when analysing the similarity of users answers (\cref{fig:rot_stats}). Moreover, participant confidence is generally worse whilst using this representation (\cref{fig:rot_corr}). Discussion with participants yielded a common theme: Given four objects rotating on screen, where some rotate in 3D and some in 4D, participants were often mislead, seeing patterns in the rotation of different cross sections, but drawing incorrect conclusions. Participants also took longer to answer when using the multi-view representation. 
It seems that users require more time and experience with this representation to take advantage of the behaviour exhibited by each perspective. 
\vskip 0.5em
The w-axis timeline did not seem notably better or worse with comparison to the control representation. The timeline representation does not provide any extra information on the rotations of a 4D object, and as such has not seemed to benefit users in interpreting the active planes of continuous rotation.
\vskip 0.5em
Unlike with the shape matching task, there is very little correlation between a participants level of confidence; measured on a scale of 0 to 10, and the correctness of their answer; measured using the jaccard index. This suggests that participants where likely, to some degree, guessing rather than being sure of their answers.
Participants did show that they felt they had a level of understanding (rated on a trinary scale of "yes", "sort of" and "no") that correlated with their level of confidence in their answers (\cref{fig:rot_corr}).
\vskip 0.5em
As might be expected, users confidence in their answer tended to decrease as they took longer to answer (\cref{fig:rot_corr}). It is likely that if a participant could not identify the active planes of rotation early on, they felt much less confident in their answer.
\vskip 0.5em
Generally a participants correctness was not affected by the shape on screen, although (\cref{fig:rot_corr}) suggests that users felt more confident whilst handling the capsule, and less so when dealing with the pentachoron. Interestingly however, participants took longer to answer when the object under rotation was the capsule.

\begin{figure}
  \centering
  \includegraphics[width=0.8\textwidth]{images/results/pose_matching_stats.png}
  \caption{Pose matching correctness and timings}
  \label{fig:pos_stats}
\end{figure}

\subsection*{Pose Matching}

TODO: pose matching
\cref{fig:pos_stats}
\cref{fig:pos_corr}

hard to draw conclusions

generally less accurate with 3D-4D and timeline

control had tightest range

3D-4D had the biggest range, but much fewer outliers, more common higher accuracy

more information, more time taken

very varied - alot of outliers

lower upper bounds over time

first 2 iterations take alot longer

faster over time



=============

ease lower as accuracy higher - odd

longer time means less easy
time taken has small increase with accuracy

more rotation when more accurate

time was longer if initial rotation was further away from a 90deg intervals
more swiping as initial rotation further from 90deg

ease higher if user had to swipe less - verified ease factor


less accurate and more time with box
more accurate with torus

less rotations with capsule and less time taken
more rotations with pentachoron

\begin{figure}
  \centering
  \includegraphics[width=0.8\textwidth]{images/results/pose_matching_correlations.png}
  \caption{Pose matching correlations. "W Count": number of interactions with the $w$ axis slider. "Swipe Count": number of rotations applied to the object. "Initial Rotation": The distance from $90^{\circ}$ of the angle of the initial pose relative to no rotation.}
  \label{fig:pos_corr}
\end{figure}

\subsection{Qualitative Results}

TODO: qualitative results

At the end of the experiment, participants were asked to complete the final section of the questionnaire (\cref{questionnaire}) they had started at the beginning of the experiment. 
This stage of the questionnaire probed users on their opinions of each extension to the 3D cross section they had interacted with during the course of the experiment. 
The summary of their opinions are listed below.

\subsubsection{w-axis Timeline}~
\vskip 0.2em
+ simple representation of geometry
+ indication of what will occur before interacting with slider
+ saved time identifying shapes
\vskip 0.5em
- hard to understand in small time frame
- lagged in browsers
- no help for rotation
%
\vskip 0.5em
\subsubsection{Multi-view}~
\vskip 0.2em
+ helpful for understanding which planes of rotation occured
+ interesting
\vskip 0.5em
- too much info
- lagged in browsers
- new users can misinterpret rotation - 3D can look like 4D from other perspectives and visa versa
%
\vskip 0.5em
\subsubsection{4D-3D}~
\vskip 0.2em
+ easy, simple
+ helps with rotation
+ easier to differentiate between multiple rotations
\vskip 0.5em
- often didnt pay attention to it except in rotation match, not to help with accuracy of pose match

\subsection{Analysis and Discussion}

TODO: analysis and discussion

\subsubsection{Representations}~
\vskip 0.2em
new users dont have enough experience to take advantage
 - more info on screen, more time taken
 - confidence was higher with less info on screen

3d to 4d good intro to differentiate 3D to 4D rotations to new users - kinda cheaty

timeline and multi-view perform worse
 - laggy in browsers
 - mostly too much info given limited time

not much beenfit when manipulating shapes
 - focus on main object

shape match - control took this least time - further indicating less info can be better
%
\vskip 0.5em
\subsubsection{Performance Over Time}~
\vskip 0.2em
correctness increase over time
 - less so for pose matching

answers would be submitted faster over time

indication that timelimit may have been too harsh for shape match
%
\vskip 0.5em
\subsubsection{Correlations Between Numerical Features}~
\vskip 0.2em
More interaction with objects increased accuracy

spending more time increased accuracy, although short timelimits did result in a trade off of good data

confidence / understanding and correctness were well correlated
 - not just blind guessing

less correct if more happening on screen - representations

%==================================================================================================================================
\chapter{Conclusion}    

TODO: conclusion

Summarise the whole project for a lazy reader who didn't read the rest (e.g. a prize-awarding committee).
\section{Guidance}
\begin{itemize}
    \item
        Summarise briefly and fairly.
    \item
        You should be addressing the general problem you introduced in the
        Introduction.        
    \item
        Include summary of concrete results (``the new compiler ran 2x
        faster'')
    \item
        Indicate what future work could be done, but remember: \textbf{you
        won't get credit for things you haven't done}.
\end{itemize}

%==================================================================================================================================
%
% 
%==================================================================================================================================
%  APPENDICES  

\begin{appendices}

\chapter{Appendices}

%\begin{itemize}
%\item
%  Copies of ethics approvals (required if obtained)
%\item
%  Extensive tables or figures that are too bulky to fit in the main body of the report, particularly ones that are repetitive and summarised in the body.
%\item 
%  Outline of the source code (e.g. directory structure), or other architecture documentation like class diagrams.
%\item 
%  User manuals, and any guides to starting/running the software.
%\end{itemize}

% Rotor Product Derivation
\begin{lstlisting}[language=python, caption={
  Rotor4 product derivation using Geometric Algebra in python: \\
  Rotor4-Vector rotation using double reflection; producing \cref{eq:rotate_vec}.\\
  Rotor4-Rotor4 product to apply a 4D Rotor to another 4D Rotor; producing \cref{eq:rotate_rotor}.
  }, label=lst:rotor_derivation]
  from sympy import symbols
  from galgebra.ga import Ga
  from galgebra.printer import Format
  
  Format(Fmode = False, Dmode = True)
  
  s4coords = (x,y,z,w) = symbols('x y z w', real=True)
  s4 = Ga('e', g=[1,1,1,1],
  coords=s4coords)
  
  def rotate_vector():
    # Vector
    a = s4.mv('a','vector')

    # Rotor
    s = s4.mv('s', 'scalar')
    b = s4.mv('b','bivector')
    p = s4.mv('p', 'pseudo')
    rotor = s + b + p
  
    (rotor * a * rotor.rev()).Fmt(3)
  
  def rotor_rotor_product
    # Rotor A
    a_s = s4.mv('a_s', 'scalar')
    a_b = s4.mv('a_b','bivector')
    a_p = s4.mv('a_p', 'pseudo')
    rotor_a = a_s + a_b + a_p
  
    # Rotor B
    b_s = s4.mv('b_s', 'scalar')
    b_b = s4.mv('b_b','bivector')
    b_p = s4.mv('b_p', 'pseudo')
    rotor_b = b_s + b_b + b_p
  
    (rotor_a * rotor_b).Fmt(3)
  
\end{lstlisting}

\begin{equation} 
  \begin{aligned}
    \label{eq:rotate_vec} 
  & + \Big( 2 a^{w} b^{xw} s + 2 a^{w} b^{xy} b^{yw} + 2 a^{w} b^{xz} b^{zw} + 2 a^{w} b^{yz} p^{xyzw} \\
  & \quad - a^{x} {\left ( b^{xw} \right )}^{2} - a^{x} {\left ( b^{xy} \right )}^{2} - a^{x} {\left ( b^{xz} \right )}^{2} + a^{x} {\left ( b^{yw} \right )}^{2} + a^{x} {\left ( b^{yz} \right )}^{2} + a^{x} {\left ( b^{zw} \right )}^{2} - a^{x} {\left ( p^{xyzw} \right )}^{2} + a^{x} s^{2} \\
  & \quad - 2 a^{y} b^{xw} b^{yw} + 2 a^{y} b^{xy} s - 2 a^{y} b^{xz} b^{yz} + 2 a^{y} b^{zw} p^{xyzw} \\
  & \quad - 2 a^{z} b^{xw} b^{zw} + 2 a^{z} b^{xy} b^{yz} + 2 a^{z} b^{xz} s - 2 a^{z} b^{yw} p^{xyzw} \Big) \boldsymbol{e}_{x} \\
  %
  & + \Big( - 2 a^{w} b^{xw} b^{xy} - 2 a^{w} b^{xz} p^{xyzw} + 2 a^{w} b^{yw} s + 2 a^{w} b^{yz} b^{zw} \\
  & \quad - 2 a^{x} b^{xw} b^{yw} - 2 a^{x} b^{xy} s - 2 a^{x} b^{xz} b^{yz} - 2 a^{x} b^{zw} p^{xyzw} \\
  & \quad + a^{y} {\left ( b^{xw} \right )}^{2} - a^{y} {\left ( b^{xy} \right )}^{2} + a^{y} {\left ( b^{xz} \right )}^{2} - a^{y} {\left ( b^{yw} \right )}^{2} - a^{y} {\left ( b^{yz} \right )}^{2} + a^{y} {\left ( b^{zw} \right )}^{2} - a^{y} {\left ( p^{xyzw} \right )}^{2} + a^{y} s^{2} \\
  & \quad + 2 a^{z} b^{xw} p^{xyzw} - 2 a^{z} b^{xy} b^{xz} - 2 a^{z} b^{yw} b^{zw} + 2 a^{z} b^{yz} s \Big) \boldsymbol{e}_{y} \\
  %
  & + \Big( - 2 a^{w} b^{xw} b^{xz} + 2 a^{w} b^{xy} p^{xyzw} - 2 a^{w} b^{yw} b^{yz} + 2 a^{w} b^{zw} s \\ 
  & \quad - 2 a^{x} b^{xw} b^{zw} + 2 a^{x} b^{xy} b^{yz} - 2 a^{x} b^{xz} s + 2 a^{x} b^{yw} p^{xyzw} \\
  & \quad - 2 a^{y} b^{xw} p^{xyzw} - 2 a^{y} b^{xy} b^{xz} - 2 a^{y} b^{yw} b^{zw} - 2 a^{y} b^{yz} s \\
  & \quad + a^{z} {\left ( b^{xw} \right )}^{2} + a^{z} {\left ( b^{xy} \right )}^{2} - a^{z} {\left ( b^{xz} \right )}^{2} + a^{z} {\left ( b^{yw} \right )}^{2} - a^{z} {\left ( b^{yz} \right )}^{2} - a^{z} {\left ( b^{zw} \right )}^{2} - a^{z} {\left ( p^{xyzw} \right )}^{2} + a^{z} s^{2} \Big) \boldsymbol{e}_{z} \\
  %
  & + \Big( - a^{w} {\left ( b^{xw} \right )}^{2} + a^{w} {\left ( b^{xy} \right )}^{2} + a^{w} {\left ( b^{xz} \right )}^{2} - a^{w} {\left ( b^{yw} \right )}^{2} + a^{w} {\left ( b^{yz} \right )}^{2} - a^{w} {\left ( b^{zw} \right )}^{2} - a^{w} {\left ( p^{xyzw} \right )}^{2} + a^{w} s^{2} \\
  & \quad - 2 a^{x} b^{xw} s + 2 a^{x} b^{xy} b^{yw} + 2 a^{x} b^{xz} b^{zw} - 2 a^{x} b^{yz} p^{xyzw} \\
  & \quad - 2 a^{y} b^{xw} b^{xy} + 2 a^{y} b^{xz} p^{xyzw} - 2 a^{y} b^{yw} s + 2 a^{y} b^{yz} b^{zw} \\
  & \quad - 2 a^{z} b^{xw} b^{xz} - 2 a^{z} b^{xy} p^{xyzw} - 2 a^{z} b^{yw} b^{yz} - 2 a^{z} b^{zw} s \Big) \boldsymbol{e}_{w}  
  \end{aligned}
\end{equation}

\begin{equation}
  \begin{aligned}[t]   
    \label{eq:rotate_rotor}
  & + \left ( - a^{xw}_{b} b^{xw}_{b} - a^{xy}_{b} b^{xy}_{b} - a^{xz}_{b} b^{xz}_{b} - a^{yw}_{b} b^{yw}_{b} - a^{yz}_{b} b^{yz}_{b} - a^{zw}_{b} b^{zw}_{b} + a^{xyzw}_{p} b^{xyzw}_{p} + a_{s} b_{s}\right )  \\  
  & + \left ( - a^{xw}_{b} b^{yw}_{b} + a^{xy}_{b} b_{s} - a^{xz}_{b} b^{yz}_{b} + a^{yw}_{b} b^{xw}_{b} + a^{yz}_{b} b^{xz}_{b} - a^{zw}_{b} b^{xyzw}_{p} - a^{xyzw}_{p} b^{zw}_{b} + a_{s} b^{xy}_{b}\right ) \boldsymbol{e}_{x}\wedge \boldsymbol{e}_{y} \\  
  & + \left ( - a^{xw}_{b} b^{zw}_{b} + a^{xy}_{b} b^{yz}_{b} + a^{xz}_{b} b_{s} + a^{yw}_{b} b^{xyzw}_{p} - a^{yz}_{b} b^{xy}_{b} + a^{zw}_{b} b^{xw}_{b} + a^{xyzw}_{p} b^{yw}_{b} + a_{s} b^{xz}_{b}\right ) \boldsymbol{e}_{x}\wedge \boldsymbol{e}_{z} \\ 
  & + \left ( a^{xw}_{b} b_{s} + a^{xy}_{b} b^{yw}_{b} + a^{xz}_{b} b^{zw}_{b} - a^{yw}_{b} b^{xy}_{b} - a^{yz}_{b} b^{xyzw}_{p} - a^{zw}_{b} b^{xz}_{b} - a^{xyzw}_{p} b^{yz}_{b} + a_{s} b^{xw}_{b}\right ) \boldsymbol{e}_{x}\wedge \boldsymbol{e}_{w} \\  
  & + \left ( - a^{xw}_{b} b^{xyzw}_{p} - a^{xy}_{b} b^{xz}_{b} + a^{xz}_{b} b^{xy}_{b} - a^{yw}_{b} b^{zw}_{b} + a^{yz}_{b} b_{s} + a^{zw}_{b} b^{yw}_{b} - a^{xyzw}_{p} b^{xw}_{b} + a_{s} b^{yz}_{b}\right ) \boldsymbol{e}_{y}\wedge \boldsymbol{e}_{z} \\  
  & + \left ( a^{xw}_{b} b^{xy}_{b} - a^{xy}_{b} b^{xw}_{b} + a^{xz}_{b} b^{xyzw}_{p} + a^{yw}_{b} b_{s} + a^{yz}_{b} b^{zw}_{b} - a^{zw}_{b} b^{yz}_{b} + a^{xyzw}_{p} b^{xz}_{b} + a_{s} b^{yw}_{b}\right ) \boldsymbol{e}_{y}\wedge \boldsymbol{e}_{w} \\ 
  & + \left ( a^{xw}_{b} b^{xz}_{b} - a^{xy}_{b} b^{xyzw}_{p} - a^{xz}_{b} b^{xw}_{b} + a^{yw}_{b} b^{yz}_{b} - a^{yz}_{b} b^{yw}_{b} + a^{zw}_{b} b_{s} - a^{xyzw}_{p} b^{xy}_{b} + a_{s} b^{zw}_{b}\right ) \boldsymbol{e}_{z}\wedge \boldsymbol{e}_{w} \\ 
  & + \left ( a^{xw}_{b} b^{yz}_{b} + a^{xy}_{b} b^{zw}_{b} - a^{xz}_{b} b^{yw}_{b} - a^{yw}_{b} b^{xz}_{b} + a^{yz}_{b} b^{xw}_{b} + a^{zw}_{b} b^{xy}_{b} + a^{xyzw}_{p} b_{s} + a_{s} b^{xyzw}_{p}\right ) \boldsymbol{e}_{x}\wedge \boldsymbol{e}_{y}\wedge \boldsymbol{e}_{z}\wedge \boldsymbol{e}_{w}  \end{aligned}
\end{equation}

\begin{lstlisting}[language=java, float, caption={
  JSON schema for data collection
}, label=lst:json]
{
  representation_name:
  {
    // repeated i times for each representation
    shape_match_i: 
    {
      loaded_shape,
      selected_shape,   // answer of suspected object
      time,             // time taken
      initial_rotor,    // object rotation: rotor components
      final_rotor,
      w_count,          // interactions with the hyperplane slider
      swipe_count,      // number of applied rotations
    }
    shape_match_i_survey
    {
      confidence,       // users confidence
      understanding,    // users understanding
    }
    rotation_match_i:
    {
      loaded_shape,
      loaded_rotation,    // boolean array of active planes of continuous rotation
      selected_rotation,  // answer of suspected planes of rotation
      time,               // time taken
    }
    rotation_match_i_survey:
    {
      confidence,       // users confidence
      understanding,    // users understanding
    }
    pose_match_i:
    {
      loaded_shape,
      time,                       // time taken
      main_object_rotor,          // final rotor components of main object
      match_object_rotor,         // final rotor components of posed object to be matched
      initial_match_object_rotor, // initial pose of the object to be matched
      w_count,                    // interactions with the hyperplane slider
      swipe_count                 // number of applied rotations
    }
    pose_match_i_survey:
    {
      ease,             // user rated ease
    }
  }
}
\end{lstlisting}

\pagebreak

%Questionnaire
\label{questionnaire}
\includepdf[width=1.1\linewidth, pages={1-4}]{images/4d_shapes_questionnaire.pdf}

\end{appendices}

%==================================================================================================================================
%   BIBLIOGRAPHY   

% The bibliography style is abbrvnat
% The bibliography always appears last, after the appendices.

\bibliographystyle{abbrvnat}

\bibliography{l4proj}

\end{document}
